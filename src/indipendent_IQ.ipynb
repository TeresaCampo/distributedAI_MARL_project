{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c740894f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IQ import train_agents, test_agents, IQLearningAgent\n",
    "from myenv_5_sparse_reward import MyGridWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdbbcc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set /distributed_project as working directory: /home/terra/Desktop/unimore/distributed_project\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "current_path = Path.cwd()\n",
    "project_root = None\n",
    "for parent in [current_path] + list(current_path.parents):\n",
    "    if parent.name == \"distributed_project\":\n",
    "        project_root = parent\n",
    "        break\n",
    "os.chdir(project_root)\n",
    "print(f\"Set /distributed_project as working directory: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de695093",
   "metadata": {},
   "source": [
    "## Train in a gridworld 9x9 (actually 7x3)\n",
    "Number of possible states: (7*3)* (7*3-1)*2 = 840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57f9dc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agnets: ['agent1', 'agent2']\n",
      "Observation space: 7\n",
      "Action space: 5\n",
      "========================================\n",
      "IQ TRAINING PHASE\n",
      "Num training episodes: 10000\n",
      "Espilon decaying rate: 0.9995\n",
      "========================================\n",
      "Episode 0/10000, Epsilon: 1.000, Episode joint_total_reward: -392\n",
      "Episode 100/10000, Epsilon: 0.951, Episode joint_total_reward: -386\n",
      "Episode 200/10000, Epsilon: 0.904, Episode joint_total_reward: -378\n",
      "Episode 300/10000, Epsilon: 0.860, Episode joint_total_reward: 198\n",
      "Episode 400/10000, Epsilon: 0.818, Episode joint_total_reward: -356\n",
      "Episode 500/10000, Epsilon: 0.778, Episode joint_total_reward: -344\n",
      "Episode 600/10000, Epsilon: 0.740, Episode joint_total_reward: 110\n",
      "Episode 700/10000, Epsilon: 0.704, Episode joint_total_reward: -326\n",
      "Episode 800/10000, Epsilon: 0.670, Episode joint_total_reward: -314\n",
      "Episode 900/10000, Epsilon: 0.637, Episode joint_total_reward: -314\n",
      "Episode 1000/10000, Epsilon: 0.606, Episode joint_total_reward: -274\n",
      "Episode 1100/10000, Epsilon: 0.577, Episode joint_total_reward: -300\n",
      "Episode 1200/10000, Epsilon: 0.548, Episode joint_total_reward: 64\n",
      "Episode 1300/10000, Epsilon: 0.522, Episode joint_total_reward: 144\n",
      "Episode 1400/10000, Epsilon: 0.496, Episode joint_total_reward: -320\n",
      "Episode 1500/10000, Epsilon: 0.472, Episode joint_total_reward: 96\n",
      "Episode 1600/10000, Epsilon: 0.449, Episode joint_total_reward: -306\n",
      "Episode 1700/10000, Epsilon: 0.427, Episode joint_total_reward: -296\n",
      "Episode 1800/10000, Epsilon: 0.406, Episode joint_total_reward: 154\n",
      "Episode 1900/10000, Epsilon: 0.386, Episode joint_total_reward: 184\n",
      "Episode 2000/10000, Epsilon: 0.368, Episode joint_total_reward: 178\n",
      "Episode 2100/10000, Epsilon: 0.350, Episode joint_total_reward: 192\n",
      "Episode 2200/10000, Epsilon: 0.333, Episode joint_total_reward: 138\n",
      "Episode 2300/10000, Epsilon: 0.316, Episode joint_total_reward: 194\n",
      "Episode 2400/10000, Epsilon: 0.301, Episode joint_total_reward: 172\n",
      "Episode 2500/10000, Epsilon: 0.286, Episode joint_total_reward: 138\n",
      "Episode 2600/10000, Epsilon: 0.272, Episode joint_total_reward: 156\n",
      "Episode 2700/10000, Epsilon: 0.259, Episode joint_total_reward: 192\n",
      "Episode 2800/10000, Epsilon: 0.246, Episode joint_total_reward: 158\n",
      "Episode 2900/10000, Epsilon: 0.234, Episode joint_total_reward: 188\n",
      "Episode 3000/10000, Epsilon: 0.223, Episode joint_total_reward: 190\n",
      "Episode 3100/10000, Epsilon: 0.212, Episode joint_total_reward: 172\n",
      "Episode 3200/10000, Epsilon: 0.202, Episode joint_total_reward: 198\n",
      "Episode 3300/10000, Epsilon: 0.192, Episode joint_total_reward: 192\n",
      "Episode 3400/10000, Epsilon: 0.183, Episode joint_total_reward: 198\n",
      "Episode 3500/10000, Epsilon: 0.174, Episode joint_total_reward: 190\n",
      "Episode 3600/10000, Epsilon: 0.165, Episode joint_total_reward: 188\n",
      "Episode 3700/10000, Epsilon: 0.157, Episode joint_total_reward: 178\n",
      "Episode 3800/10000, Epsilon: 0.149, Episode joint_total_reward: 200\n",
      "Episode 3900/10000, Epsilon: 0.142, Episode joint_total_reward: 184\n",
      "Episode 4000/10000, Epsilon: 0.135, Episode joint_total_reward: 194\n",
      "Episode 4100/10000, Epsilon: 0.129, Episode joint_total_reward: 196\n",
      "Episode 4200/10000, Epsilon: 0.122, Episode joint_total_reward: 192\n",
      "Episode 4300/10000, Epsilon: 0.116, Episode joint_total_reward: 174\n",
      "Episode 4400/10000, Epsilon: 0.111, Episode joint_total_reward: 192\n",
      "Episode 4500/10000, Epsilon: 0.105, Episode joint_total_reward: 196\n",
      "Episode 4600/10000, Epsilon: 0.100, Episode joint_total_reward: 196\n",
      "Episode 4700/10000, Epsilon: 0.095, Episode joint_total_reward: 200\n",
      "Episode 4800/10000, Epsilon: 0.091, Episode joint_total_reward: 198\n",
      "Episode 4900/10000, Epsilon: 0.086, Episode joint_total_reward: 198\n",
      "Episode 5000/10000, Epsilon: 0.082, Episode joint_total_reward: 188\n",
      "Episode 5100/10000, Epsilon: 0.078, Episode joint_total_reward: 196\n",
      "Episode 5200/10000, Epsilon: 0.074, Episode joint_total_reward: 200\n",
      "Episode 5300/10000, Epsilon: 0.071, Episode joint_total_reward: 200\n",
      "Episode 5400/10000, Epsilon: 0.067, Episode joint_total_reward: 196\n",
      "Episode 5500/10000, Epsilon: 0.064, Episode joint_total_reward: 194\n",
      "Episode 5600/10000, Epsilon: 0.061, Episode joint_total_reward: 194\n",
      "Episode 5700/10000, Epsilon: 0.058, Episode joint_total_reward: 196\n",
      "Episode 5800/10000, Epsilon: 0.055, Episode joint_total_reward: 200\n",
      "Episode 5900/10000, Epsilon: 0.052, Episode joint_total_reward: 192\n",
      "Episode 6000/10000, Epsilon: 0.050, Episode joint_total_reward: 194\n",
      "Episode 6100/10000, Epsilon: 0.047, Episode joint_total_reward: 200\n",
      "Episode 6200/10000, Epsilon: 0.045, Episode joint_total_reward: 192\n",
      "Episode 6300/10000, Epsilon: 0.043, Episode joint_total_reward: 196\n",
      "Episode 6400/10000, Epsilon: 0.041, Episode joint_total_reward: 196\n",
      "Episode 6500/10000, Epsilon: 0.039, Episode joint_total_reward: 194\n",
      "Episode 6600/10000, Epsilon: 0.037, Episode joint_total_reward: 200\n",
      "Episode 6700/10000, Epsilon: 0.035, Episode joint_total_reward: 194\n",
      "Episode 6800/10000, Epsilon: 0.033, Episode joint_total_reward: 198\n",
      "Episode 6900/10000, Epsilon: 0.032, Episode joint_total_reward: 194\n",
      "Episode 7000/10000, Epsilon: 0.030, Episode joint_total_reward: 196\n",
      "Episode 7100/10000, Epsilon: 0.029, Episode joint_total_reward: 200\n",
      "Episode 7200/10000, Epsilon: 0.027, Episode joint_total_reward: 196\n",
      "Episode 7300/10000, Epsilon: 0.026, Episode joint_total_reward: 200\n",
      "Episode 7400/10000, Epsilon: 0.025, Episode joint_total_reward: 200\n",
      "Episode 7500/10000, Epsilon: 0.023, Episode joint_total_reward: 198\n",
      "Episode 7600/10000, Epsilon: 0.022, Episode joint_total_reward: 194\n",
      "Episode 7700/10000, Epsilon: 0.021, Episode joint_total_reward: 196\n",
      "Episode 7800/10000, Epsilon: 0.020, Episode joint_total_reward: 198\n",
      "Episode 7900/10000, Epsilon: 0.019, Episode joint_total_reward: 198\n",
      "Episode 8000/10000, Epsilon: 0.018, Episode joint_total_reward: 192\n",
      "Episode 8100/10000, Epsilon: 0.017, Episode joint_total_reward: 190\n",
      "Episode 8200/10000, Epsilon: 0.017, Episode joint_total_reward: 196\n",
      "Episode 8300/10000, Epsilon: 0.016, Episode joint_total_reward: 196\n",
      "Episode 8400/10000, Epsilon: 0.015, Episode joint_total_reward: 196\n",
      "Episode 8500/10000, Epsilon: 0.014, Episode joint_total_reward: 198\n",
      "Episode 8600/10000, Epsilon: 0.014, Episode joint_total_reward: 190\n",
      "Episode 8700/10000, Epsilon: 0.013, Episode joint_total_reward: 198\n",
      "Episode 8800/10000, Epsilon: 0.012, Episode joint_total_reward: 196\n",
      "Episode 8900/10000, Epsilon: 0.012, Episode joint_total_reward: 200\n",
      "Episode 9000/10000, Epsilon: 0.011, Episode joint_total_reward: 196\n",
      "Episode 9100/10000, Epsilon: 0.011, Episode joint_total_reward: 194\n",
      "Episode 9200/10000, Epsilon: 0.010, Episode joint_total_reward: 200\n",
      "Episode 9300/10000, Epsilon: 0.010, Episode joint_total_reward: 200\n",
      "Episode 9400/10000, Epsilon: 0.010, Episode joint_total_reward: 200\n",
      "Episode 9500/10000, Epsilon: 0.010, Episode joint_total_reward: 200\n",
      "Episode 9600/10000, Epsilon: 0.010, Episode joint_total_reward: 200\n",
      "Episode 9700/10000, Epsilon: 0.010, Episode joint_total_reward: 194\n",
      "Episode 9800/10000, Epsilon: 0.010, Episode joint_total_reward: 192\n",
      "Episode 9900/10000, Epsilon: 0.010, Episode joint_total_reward: 200\n",
      "END OF IQ TRAINING PHASE\n"
     ]
    }
   ],
   "source": [
    "GRID_SIZE = 9\n",
    "\n",
    "env = MyGridWorld(grid_size=GRID_SIZE)\n",
    "agents = {}\n",
    "action_size = env.action_space(\"agent1\").n\n",
    "obs_shape = env.observation_space(\"agent1\").shape[0]\n",
    "\n",
    "print(f\"Agnets: {env.possible_agents}\\nObservation space: {obs_shape}\\nAction space: {action_size}\")\n",
    "\n",
    "for agent_id in env.possible_agents:\n",
    "    agents[agent_id] = IQLearningAgent(\n",
    "        agent_id=agent_id, \n",
    "        action_space_size=action_size, \n",
    "        obs_space_shape=obs_shape,\n",
    "        learning_rate=0.1, \n",
    "        discount_factor=0.85,\n",
    "        epsilon=1 # High initial exploration\n",
    "    )\n",
    "\n",
    "NUM_EPISODES = 10000\n",
    "EPSILON_DECAY_RATE = 0.9995\n",
    "MIN_EPSILON = 0.01\n",
    "\n",
    "# TRAINING \n",
    "trained_agents = train_agents(\n",
    "    env, \n",
    "    agents, \n",
    "    NUM_EPISODES, \n",
    "    EPSILON_DECAY_RATE, \n",
    "    MIN_EPSILON\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fc876fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "IQ TEST PHASE\n",
      "Num testing episodes: 100\n",
      "========================================\n",
      "Test Ep. 1/100: Status=SUCCESS, Reward=196.00, Steps=4\n",
      "Test Ep. 21/100: Status=SUCCESS, Reward=198.00, Steps=5\n",
      "Test Ep. 41/100: Status=SUCCESS, Reward=196.00, Steps=4\n",
      "Test Ep. 61/100: Status=SUCCESS, Reward=194.00, Steps=7\n",
      "Test Ep. 81/100: Status=SUCCESS, Reward=200.00, Steps=5\n",
      "END OF IQ TESTING PHASE\n",
      "\n",
      "========================================\n",
      "TEST METRICS\n",
      "Success rate: 100.00%\n",
      "Avg reward per episode: 196.70\n",
      "Avg steps per episode: 4.99\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "env_test = MyGridWorld(grid_size=GRID_SIZE) \n",
    "test_agents(env_test, trained_agents, num_test_episodes=100)\n",
    "\n",
    "env.close()\n",
    "env_test.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8406bf57",
   "metadata": {},
   "source": [
    "## Train in a gridworld 10x10 (actually 8x4)\n",
    "Number of possible states: (8*4)* (8*4-1)*2 = 1984"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "105d49d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agnets: ['agent1', 'agent2']\n",
      "Observation space: 7\n",
      "Action space: 5\n",
      "========================================\n",
      "IQ TRAINING PHASE\n",
      "Num training episodes: 10000\n",
      "Espilon decaying rate: 0.9995\n",
      "========================================\n",
      "Episode 0/10000, Epsilon: 1.000, Episode joint_total_reward: -384\n",
      "Episode 100/10000, Epsilon: 0.951, Episode joint_total_reward: -390\n",
      "Episode 200/10000, Epsilon: 0.904, Episode joint_total_reward: -396\n",
      "Episode 300/10000, Epsilon: 0.860, Episode joint_total_reward: -398\n",
      "Episode 400/10000, Epsilon: 0.818, Episode joint_total_reward: -376\n",
      "Episode 500/10000, Epsilon: 0.778, Episode joint_total_reward: -358\n",
      "Episode 600/10000, Epsilon: 0.740, Episode joint_total_reward: -306\n",
      "Episode 700/10000, Epsilon: 0.704, Episode joint_total_reward: 194\n",
      "Episode 800/10000, Epsilon: 0.670, Episode joint_total_reward: -350\n",
      "Episode 900/10000, Epsilon: 0.637, Episode joint_total_reward: -332\n",
      "Episode 1000/10000, Epsilon: 0.606, Episode joint_total_reward: 126\n",
      "Episode 1100/10000, Epsilon: 0.577, Episode joint_total_reward: -348\n",
      "Episode 1200/10000, Epsilon: 0.548, Episode joint_total_reward: -336\n",
      "Episode 1300/10000, Epsilon: 0.522, Episode joint_total_reward: -330\n",
      "Episode 1400/10000, Epsilon: 0.496, Episode joint_total_reward: -344\n",
      "Episode 1500/10000, Epsilon: 0.472, Episode joint_total_reward: -362\n",
      "Episode 1600/10000, Epsilon: 0.449, Episode joint_total_reward: -328\n",
      "Episode 1700/10000, Epsilon: 0.427, Episode joint_total_reward: -344\n",
      "Episode 1800/10000, Epsilon: 0.406, Episode joint_total_reward: -304\n",
      "Episode 1900/10000, Epsilon: 0.386, Episode joint_total_reward: 152\n",
      "Episode 2000/10000, Epsilon: 0.368, Episode joint_total_reward: 86\n",
      "Episode 2100/10000, Epsilon: 0.350, Episode joint_total_reward: 176\n",
      "Episode 2200/10000, Epsilon: 0.333, Episode joint_total_reward: 154\n",
      "Episode 2300/10000, Epsilon: 0.316, Episode joint_total_reward: 162\n",
      "Episode 2400/10000, Epsilon: 0.301, Episode joint_total_reward: 136\n",
      "Episode 2500/10000, Epsilon: 0.286, Episode joint_total_reward: -310\n",
      "Episode 2600/10000, Epsilon: 0.272, Episode joint_total_reward: -380\n",
      "Episode 2700/10000, Epsilon: 0.259, Episode joint_total_reward: 64\n",
      "Episode 2800/10000, Epsilon: 0.246, Episode joint_total_reward: -348\n",
      "Episode 2900/10000, Epsilon: 0.234, Episode joint_total_reward: 56\n",
      "Episode 3000/10000, Epsilon: 0.223, Episode joint_total_reward: 152\n",
      "Episode 3100/10000, Epsilon: 0.212, Episode joint_total_reward: -332\n",
      "Episode 3200/10000, Epsilon: 0.202, Episode joint_total_reward: 138\n",
      "Episode 3300/10000, Epsilon: 0.192, Episode joint_total_reward: 146\n",
      "Episode 3400/10000, Epsilon: 0.183, Episode joint_total_reward: -388\n",
      "Episode 3500/10000, Epsilon: 0.174, Episode joint_total_reward: -396\n",
      "Episode 3600/10000, Epsilon: 0.165, Episode joint_total_reward: -362\n",
      "Episode 3700/10000, Epsilon: 0.157, Episode joint_total_reward: -384\n",
      "Episode 3800/10000, Epsilon: 0.149, Episode joint_total_reward: -380\n",
      "Episode 3900/10000, Epsilon: 0.142, Episode joint_total_reward: -398\n",
      "Episode 4000/10000, Epsilon: 0.135, Episode joint_total_reward: -392\n",
      "Episode 4100/10000, Epsilon: 0.129, Episode joint_total_reward: -368\n",
      "Episode 4200/10000, Epsilon: 0.122, Episode joint_total_reward: -398\n",
      "Episode 4300/10000, Epsilon: 0.116, Episode joint_total_reward: -394\n",
      "Episode 4400/10000, Epsilon: 0.111, Episode joint_total_reward: -364\n",
      "Episode 4500/10000, Epsilon: 0.105, Episode joint_total_reward: 182\n",
      "Episode 4600/10000, Epsilon: 0.100, Episode joint_total_reward: -388\n",
      "Episode 4700/10000, Epsilon: 0.095, Episode joint_total_reward: -398\n",
      "Episode 4800/10000, Epsilon: 0.091, Episode joint_total_reward: -376\n",
      "Episode 4900/10000, Epsilon: 0.086, Episode joint_total_reward: -388\n",
      "Episode 5000/10000, Epsilon: 0.082, Episode joint_total_reward: -392\n",
      "Episode 5100/10000, Epsilon: 0.078, Episode joint_total_reward: -388\n",
      "Episode 5200/10000, Epsilon: 0.074, Episode joint_total_reward: -396\n",
      "Episode 5300/10000, Epsilon: 0.071, Episode joint_total_reward: -358\n",
      "Episode 5400/10000, Epsilon: 0.067, Episode joint_total_reward: -358\n",
      "Episode 5500/10000, Epsilon: 0.064, Episode joint_total_reward: -382\n",
      "Episode 5600/10000, Epsilon: 0.061, Episode joint_total_reward: -368\n",
      "Episode 5700/10000, Epsilon: 0.058, Episode joint_total_reward: -360\n",
      "Episode 5800/10000, Epsilon: 0.055, Episode joint_total_reward: -390\n",
      "Episode 5900/10000, Epsilon: 0.052, Episode joint_total_reward: -382\n",
      "Episode 6000/10000, Epsilon: 0.050, Episode joint_total_reward: -398\n",
      "Episode 6100/10000, Epsilon: 0.047, Episode joint_total_reward: -386\n",
      "Episode 6200/10000, Epsilon: 0.045, Episode joint_total_reward: -374\n",
      "Episode 6300/10000, Epsilon: 0.043, Episode joint_total_reward: -390\n",
      "Episode 6400/10000, Epsilon: 0.041, Episode joint_total_reward: -398\n",
      "Episode 6500/10000, Epsilon: 0.039, Episode joint_total_reward: -390\n",
      "Episode 6600/10000, Epsilon: 0.037, Episode joint_total_reward: -362\n",
      "Episode 6700/10000, Epsilon: 0.035, Episode joint_total_reward: -368\n",
      "Episode 6800/10000, Epsilon: 0.033, Episode joint_total_reward: -398\n",
      "Episode 6900/10000, Epsilon: 0.032, Episode joint_total_reward: 182\n",
      "Episode 7000/10000, Epsilon: 0.030, Episode joint_total_reward: 196\n",
      "Episode 7100/10000, Epsilon: 0.029, Episode joint_total_reward: 154\n",
      "Episode 7200/10000, Epsilon: 0.027, Episode joint_total_reward: -390\n",
      "Episode 7300/10000, Epsilon: 0.026, Episode joint_total_reward: -372\n",
      "Episode 7400/10000, Epsilon: 0.025, Episode joint_total_reward: -392\n",
      "Episode 7500/10000, Epsilon: 0.023, Episode joint_total_reward: 168\n",
      "Episode 7600/10000, Epsilon: 0.022, Episode joint_total_reward: -396\n",
      "Episode 7700/10000, Epsilon: 0.021, Episode joint_total_reward: 176\n",
      "Episode 7800/10000, Epsilon: 0.020, Episode joint_total_reward: -392\n",
      "Episode 7900/10000, Epsilon: 0.019, Episode joint_total_reward: -380\n",
      "Episode 8000/10000, Epsilon: 0.018, Episode joint_total_reward: 200\n",
      "Episode 8100/10000, Epsilon: 0.017, Episode joint_total_reward: -334\n",
      "Episode 8200/10000, Epsilon: 0.017, Episode joint_total_reward: -394\n",
      "Episode 8300/10000, Epsilon: 0.016, Episode joint_total_reward: 68\n",
      "Episode 8400/10000, Epsilon: 0.015, Episode joint_total_reward: -398\n",
      "Episode 8500/10000, Epsilon: 0.014, Episode joint_total_reward: -328\n",
      "Episode 8600/10000, Epsilon: 0.014, Episode joint_total_reward: 152\n",
      "Episode 8700/10000, Epsilon: 0.013, Episode joint_total_reward: -310\n",
      "Episode 8800/10000, Epsilon: 0.012, Episode joint_total_reward: 100\n",
      "Episode 8900/10000, Epsilon: 0.012, Episode joint_total_reward: -364\n",
      "Episode 9000/10000, Epsilon: 0.011, Episode joint_total_reward: 138\n",
      "Episode 9100/10000, Epsilon: 0.011, Episode joint_total_reward: -372\n",
      "Episode 9200/10000, Epsilon: 0.010, Episode joint_total_reward: 106\n",
      "Episode 9300/10000, Epsilon: 0.010, Episode joint_total_reward: -368\n",
      "Episode 9400/10000, Epsilon: 0.010, Episode joint_total_reward: 156\n",
      "Episode 9500/10000, Epsilon: 0.010, Episode joint_total_reward: 170\n",
      "Episode 9600/10000, Epsilon: 0.010, Episode joint_total_reward: -358\n",
      "Episode 9700/10000, Epsilon: 0.010, Episode joint_total_reward: 188\n",
      "Episode 9800/10000, Epsilon: 0.010, Episode joint_total_reward: 140\n",
      "Episode 9900/10000, Epsilon: 0.010, Episode joint_total_reward: 134\n",
      "END OF IQ TRAINING PHASE\n"
     ]
    }
   ],
   "source": [
    "GRID_SIZE = 10\n",
    "\n",
    "env = MyGridWorld(grid_size=GRID_SIZE)\n",
    "agents = {}\n",
    "action_size = env.action_space(\"agent1\").n\n",
    "obs_shape = env.observation_space(\"agent1\").shape[0]\n",
    "\n",
    "print(f\"Agnets: {env.possible_agents}\\nObservation space: {obs_shape}\\nAction space: {action_size}\")\n",
    "\n",
    "for agent_id in env.possible_agents:\n",
    "    agents[agent_id] = IQLearningAgent(\n",
    "        agent_id=agent_id, \n",
    "        action_space_size=action_size, \n",
    "        obs_space_shape=obs_shape,\n",
    "        learning_rate=0.1, \n",
    "        discount_factor=0.85,\n",
    "        epsilon=1 # High initial exploration\n",
    "    )\n",
    "\n",
    "NUM_EPISODES = 10000\n",
    "EPSILON_DECAY_RATE = 0.9995\n",
    "MIN_EPSILON = 0.01\n",
    "\n",
    "# TRAINING \n",
    "trained_agents = train_agents(\n",
    "    env, \n",
    "    agents, \n",
    "    NUM_EPISODES, \n",
    "    EPSILON_DECAY_RATE, \n",
    "    MIN_EPSILON\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6fc411e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "IQ TEST PHASE\n",
      "Num testing episodes: 100\n",
      "========================================\n",
      "Test Ep. 1/100: Status=SUCCESS, Reward=156.00, Steps=24\n",
      "Test Ep. 21/100: Status=TRUNCATED, Reward=-398.00, Steps=100\n",
      "Test Ep. 41/100: Status=SUCCESS, Reward=164.00, Steps=20\n",
      "Test Ep. 61/100: Status=SUCCESS, Reward=136.00, Steps=42\n",
      "Test Ep. 81/100: Status=TRUNCATED, Reward=-398.00, Steps=100\n",
      "END OF IQ TESTING PHASE\n",
      "\n",
      "========================================\n",
      "TEST METRICS\n",
      "Success rate: 88.00%\n",
      "Avg reward per episode: 92.50\n",
      "Avg steps per episode: 33.27\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "env_test = MyGridWorld(grid_size=GRID_SIZE) \n",
    "test_agents(env_test, trained_agents, num_test_episodes=100)\n",
    "\n",
    "env.close()\n",
    "env_test.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d5d32",
   "metadata": {},
   "source": [
    "## Train in a gridworld 11x11 (actually 9x5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb122099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agnets: ['agent1', 'agent2']\n",
      "Observation space: 7\n",
      "Action space: 5\n",
      "========================================\n",
      "IQ TRAINING PHASE\n",
      "Num training episodes: 10000\n",
      "Espilon decaying rate: 0.9995\n",
      "========================================\n",
      "Episode 0/10000, Epsilon: 1.000, Episode joint_total_reward: -384\n",
      "Episode 100/10000, Epsilon: 0.951, Episode joint_total_reward: -388\n",
      "Episode 200/10000, Epsilon: 0.904, Episode joint_total_reward: -394\n",
      "Episode 300/10000, Epsilon: 0.860, Episode joint_total_reward: -366\n",
      "Episode 400/10000, Epsilon: 0.818, Episode joint_total_reward: -386\n",
      "Episode 500/10000, Epsilon: 0.778, Episode joint_total_reward: -398\n",
      "Episode 600/10000, Epsilon: 0.740, Episode joint_total_reward: -398\n",
      "Episode 700/10000, Epsilon: 0.704, Episode joint_total_reward: -338\n",
      "Episode 800/10000, Epsilon: 0.670, Episode joint_total_reward: -370\n",
      "Episode 900/10000, Epsilon: 0.637, Episode joint_total_reward: -366\n",
      "Episode 1000/10000, Epsilon: 0.606, Episode joint_total_reward: -332\n",
      "Episode 1100/10000, Epsilon: 0.577, Episode joint_total_reward: -398\n",
      "Episode 1200/10000, Epsilon: 0.548, Episode joint_total_reward: -360\n",
      "Episode 1300/10000, Epsilon: 0.522, Episode joint_total_reward: -332\n",
      "Episode 1400/10000, Epsilon: 0.496, Episode joint_total_reward: -354\n",
      "Episode 1500/10000, Epsilon: 0.472, Episode joint_total_reward: -324\n",
      "Episode 1600/10000, Epsilon: 0.449, Episode joint_total_reward: -382\n",
      "Episode 1700/10000, Epsilon: 0.427, Episode joint_total_reward: 108\n",
      "Episode 1800/10000, Epsilon: 0.406, Episode joint_total_reward: -346\n",
      "Episode 1900/10000, Epsilon: 0.386, Episode joint_total_reward: 180\n",
      "Episode 2000/10000, Epsilon: 0.368, Episode joint_total_reward: -356\n",
      "Episode 2100/10000, Epsilon: 0.350, Episode joint_total_reward: -342\n",
      "Episode 2200/10000, Epsilon: 0.333, Episode joint_total_reward: -370\n",
      "Episode 2300/10000, Epsilon: 0.316, Episode joint_total_reward: 92\n",
      "Episode 2400/10000, Epsilon: 0.301, Episode joint_total_reward: -312\n",
      "Episode 2500/10000, Epsilon: 0.286, Episode joint_total_reward: -332\n",
      "Episode 2600/10000, Epsilon: 0.272, Episode joint_total_reward: -368\n",
      "Episode 2700/10000, Epsilon: 0.259, Episode joint_total_reward: -338\n",
      "Episode 2800/10000, Epsilon: 0.246, Episode joint_total_reward: -374\n",
      "Episode 2900/10000, Epsilon: 0.234, Episode joint_total_reward: -316\n",
      "Episode 3000/10000, Epsilon: 0.223, Episode joint_total_reward: -340\n",
      "Episode 3100/10000, Epsilon: 0.212, Episode joint_total_reward: -376\n",
      "Episode 3200/10000, Epsilon: 0.202, Episode joint_total_reward: -368\n",
      "Episode 3300/10000, Epsilon: 0.192, Episode joint_total_reward: -370\n",
      "Episode 3400/10000, Epsilon: 0.183, Episode joint_total_reward: -380\n",
      "Episode 3500/10000, Epsilon: 0.174, Episode joint_total_reward: -368\n",
      "Episode 3600/10000, Epsilon: 0.165, Episode joint_total_reward: -388\n",
      "Episode 3700/10000, Epsilon: 0.157, Episode joint_total_reward: -376\n",
      "Episode 3800/10000, Epsilon: 0.149, Episode joint_total_reward: -390\n",
      "Episode 3900/10000, Epsilon: 0.142, Episode joint_total_reward: -398\n",
      "Episode 4000/10000, Epsilon: 0.135, Episode joint_total_reward: -370\n",
      "Episode 4100/10000, Epsilon: 0.129, Episode joint_total_reward: -398\n",
      "Episode 4200/10000, Epsilon: 0.122, Episode joint_total_reward: -388\n",
      "Episode 4300/10000, Epsilon: 0.116, Episode joint_total_reward: -372\n",
      "Episode 4400/10000, Epsilon: 0.111, Episode joint_total_reward: -382\n",
      "Episode 4500/10000, Epsilon: 0.105, Episode joint_total_reward: -392\n",
      "Episode 4600/10000, Epsilon: 0.100, Episode joint_total_reward: -386\n",
      "Episode 4700/10000, Epsilon: 0.095, Episode joint_total_reward: -390\n",
      "Episode 4800/10000, Epsilon: 0.091, Episode joint_total_reward: -390\n",
      "Episode 4900/10000, Epsilon: 0.086, Episode joint_total_reward: -398\n",
      "Episode 5000/10000, Epsilon: 0.082, Episode joint_total_reward: -386\n",
      "Episode 5100/10000, Epsilon: 0.078, Episode joint_total_reward: -386\n",
      "Episode 5200/10000, Epsilon: 0.074, Episode joint_total_reward: 92\n",
      "Episode 5300/10000, Epsilon: 0.071, Episode joint_total_reward: 150\n",
      "Episode 5400/10000, Epsilon: 0.067, Episode joint_total_reward: -394\n",
      "Episode 5500/10000, Epsilon: 0.064, Episode joint_total_reward: -382\n",
      "Episode 5600/10000, Epsilon: 0.061, Episode joint_total_reward: -398\n",
      "Episode 5700/10000, Epsilon: 0.058, Episode joint_total_reward: -392\n",
      "Episode 5800/10000, Epsilon: 0.055, Episode joint_total_reward: 132\n",
      "Episode 5900/10000, Epsilon: 0.052, Episode joint_total_reward: -364\n",
      "Episode 6000/10000, Epsilon: 0.050, Episode joint_total_reward: -380\n",
      "Episode 6100/10000, Epsilon: 0.047, Episode joint_total_reward: -394\n",
      "Episode 6200/10000, Epsilon: 0.045, Episode joint_total_reward: -392\n",
      "Episode 6300/10000, Epsilon: 0.043, Episode joint_total_reward: -390\n",
      "Episode 6400/10000, Epsilon: 0.041, Episode joint_total_reward: -396\n",
      "Episode 6500/10000, Epsilon: 0.039, Episode joint_total_reward: -390\n",
      "Episode 6600/10000, Epsilon: 0.037, Episode joint_total_reward: -398\n",
      "Episode 6700/10000, Epsilon: 0.035, Episode joint_total_reward: -388\n",
      "Episode 6800/10000, Epsilon: 0.033, Episode joint_total_reward: -392\n",
      "Episode 6900/10000, Epsilon: 0.032, Episode joint_total_reward: -394\n",
      "Episode 7000/10000, Epsilon: 0.030, Episode joint_total_reward: -388\n",
      "Episode 7100/10000, Epsilon: 0.029, Episode joint_total_reward: -388\n",
      "Episode 7200/10000, Epsilon: 0.027, Episode joint_total_reward: -396\n",
      "Episode 7300/10000, Epsilon: 0.026, Episode joint_total_reward: -394\n",
      "Episode 7400/10000, Epsilon: 0.025, Episode joint_total_reward: -284\n",
      "Episode 7500/10000, Epsilon: 0.023, Episode joint_total_reward: -380\n",
      "Episode 7600/10000, Epsilon: 0.022, Episode joint_total_reward: -398\n",
      "Episode 7700/10000, Epsilon: 0.021, Episode joint_total_reward: -392\n",
      "Episode 7800/10000, Epsilon: 0.020, Episode joint_total_reward: -390\n",
      "Episode 7900/10000, Epsilon: 0.019, Episode joint_total_reward: -386\n",
      "Episode 8000/10000, Epsilon: 0.018, Episode joint_total_reward: -388\n",
      "Episode 8100/10000, Epsilon: 0.017, Episode joint_total_reward: -388\n",
      "Episode 8200/10000, Epsilon: 0.017, Episode joint_total_reward: -380\n",
      "Episode 8300/10000, Epsilon: 0.016, Episode joint_total_reward: -398\n",
      "Episode 8400/10000, Epsilon: 0.015, Episode joint_total_reward: -396\n",
      "Episode 8500/10000, Epsilon: 0.014, Episode joint_total_reward: -384\n",
      "Episode 8600/10000, Epsilon: 0.014, Episode joint_total_reward: -394\n",
      "Episode 8700/10000, Epsilon: 0.013, Episode joint_total_reward: -396\n",
      "Episode 8800/10000, Epsilon: 0.012, Episode joint_total_reward: -390\n",
      "Episode 8900/10000, Epsilon: 0.012, Episode joint_total_reward: -392\n",
      "Episode 9000/10000, Epsilon: 0.011, Episode joint_total_reward: -386\n",
      "Episode 9100/10000, Epsilon: 0.011, Episode joint_total_reward: -384\n",
      "Episode 9200/10000, Epsilon: 0.010, Episode joint_total_reward: -378\n",
      "Episode 9300/10000, Epsilon: 0.010, Episode joint_total_reward: -386\n",
      "Episode 9400/10000, Epsilon: 0.010, Episode joint_total_reward: -396\n",
      "Episode 9500/10000, Epsilon: 0.010, Episode joint_total_reward: -392\n",
      "Episode 9600/10000, Epsilon: 0.010, Episode joint_total_reward: -390\n",
      "Episode 9700/10000, Epsilon: 0.010, Episode joint_total_reward: -388\n",
      "Episode 9800/10000, Epsilon: 0.010, Episode joint_total_reward: -386\n",
      "Episode 9900/10000, Epsilon: 0.010, Episode joint_total_reward: -324\n",
      "END OF IQ TRAINING PHASE\n"
     ]
    }
   ],
   "source": [
    "GRID_SIZE = 11\n",
    "\n",
    "env = MyGridWorld(grid_size=GRID_SIZE)\n",
    "agents = {}\n",
    "action_size = env.action_space(\"agent1\").n\n",
    "obs_shape = env.observation_space(\"agent1\").shape[0]\n",
    "\n",
    "print(f\"Agnets: {env.possible_agents}\\nObservation space: {obs_shape}\\nAction space: {action_size}\")\n",
    "\n",
    "for agent_id in env.possible_agents:\n",
    "    agents[agent_id] = IQLearningAgent(\n",
    "        agent_id=agent_id, \n",
    "        action_space_size=action_size, \n",
    "        obs_space_shape=obs_shape,\n",
    "        learning_rate=0.1, \n",
    "        discount_factor=0.85,\n",
    "        epsilon=1 # High initial exploration\n",
    "    )\n",
    "\n",
    "NUM_EPISODES = 10000\n",
    "EPSILON_DECAY_RATE = 0.9995\n",
    "MIN_EPSILON = 0.01\n",
    "\n",
    "# TRAINING \n",
    "trained_agents = train_agents(\n",
    "    env, \n",
    "    agents, \n",
    "    NUM_EPISODES, \n",
    "    EPSILON_DECAY_RATE, \n",
    "    MIN_EPSILON\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49c730ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "IQ TEST PHASE\n",
      "Num testing episodes: 100\n",
      "========================================\n",
      "Test Ep. 1/100: Status=TRUNCATED, Reward=-384.00, Steps=100\n",
      "Test Ep. 21/100: Status=TRUNCATED, Reward=-394.00, Steps=100\n",
      "Test Ep. 41/100: Status=TRUNCATED, Reward=-398.00, Steps=100\n",
      "Test Ep. 61/100: Status=TRUNCATED, Reward=-398.00, Steps=100\n",
      "Test Ep. 81/100: Status=TRUNCATED, Reward=-398.00, Steps=100\n",
      "END OF IQ TESTING PHASE\n",
      "\n",
      "========================================\n",
      "TEST METRICS\n",
      "Success rate: 0.00%\n",
      "Avg reward per episode: -387.16\n",
      "Avg steps per episode: 100.00\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "env_test = MyGridWorld(grid_size=GRID_SIZE) \n",
    "test_agents(env_test, trained_agents, num_test_episodes=100)\n",
    "\n",
    "env.close()\n",
    "env_test.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MARL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
