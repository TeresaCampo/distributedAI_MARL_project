{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b3cd819",
   "metadata": {},
   "source": [
    "# **My custom env - dense reward**\n",
    "\n",
    "**Environment classe pasted here in order to make it accessible to all the workers of Ray.**\n",
    "\n",
    "It is equivalent to /myenv_6_dense_reward.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "125ef575",
   "metadata": {},
   "outputs": [],
   "source": [
    "under_examination = \"looseplay_2agents_densereward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b94dc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project dir found: /home/terra/Desktop/magistrale/distributed_ai_project\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path(os.getcwd()) \n",
    "pointed_dir = current_dir\n",
    "\n",
    "while True:\n",
    "    if pointed_dir.is_dir() and \"distributed_ai_project\" == str(pointed_dir).split(\"/\")[-1]:\n",
    "        project_dir = pointed_dir\n",
    "        print(f\"Project dir found: {project_dir}\")\n",
    "        break\n",
    "    \n",
    "    if pointed_dir == pointed_dir.parent:\n",
    "        print(\"Error while looking for 'distributed_project', project dir\")\n",
    "        break\n",
    "        \n",
    "    pointed_dir = pointed_dir.parent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2a20e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import functools\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from pettingzoo import ParallelEnv\n",
    "import pygame \n",
    "import os\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "SPRITES_DIR = f\"{project_dir}/sprites\"\n",
    "\n",
    "\n",
    "class MyGridWorld(ParallelEnv):\n",
    "    metadata = {\"render_modes\": [\"human\"], \"name\": \"custom_grid_v0\"}\n",
    "\n",
    "    def __init__(self, render_mode=None, n_agents = 2, grid_size=15, vision_radius = 5):\n",
    "        if grid_size<8:\n",
    "            print(\"Error, need to insert a grid size greater or equal to 8\")\n",
    "        self.grid_size = grid_size\n",
    "        self.render_mode = render_mode\n",
    "        self.vision_radius = vision_radius\n",
    "        ######## Agents, fixed components, and forbidden positions\n",
    "        self.possible_agents = [f\"agent{i}\" for i in range(1, n_agents+1)]\n",
    "        self.agents = self.possible_agents[:]\n",
    "        self.gate_open = False\n",
    "\n",
    "        self.fixed_components = {\n",
    "            \"button1\":  {\"pos\": np.array([self.grid_size//2+2, 1+3+2]), \"file\": \"button.png\"},\n",
    "            \"button2\":  {\"pos\": np.array([self.grid_size//2+2, 1+1]), \"file\": \"button.png\"},\n",
    "\n",
    "            \"gate_open\":  {\"pos\": np.array([self.grid_size//2, 1+3]), \"file\": \"gate_open.png\"},\n",
    "            \"gate_close\":  {\"pos\": np.array([self.grid_size//2, 1+3]), \"file\": \"gate_close.png\"}   \n",
    "        }\n",
    "        self.button1_pos = self.fixed_components[\"button1\"][\"pos\"]\n",
    "        self.button2_pos = self.fixed_components[\"button2\"][\"pos\"]\n",
    "\n",
    "        self.gate_pos = self.fixed_components[\"gate_open\"][\"pos\"] \n",
    "        self.target_final_pos = self.gate_pos+[0, -1]\n",
    "\n",
    "        self.x_range = (1, self.grid_size-1-1)\n",
    "        self.y_range = (1+3+1, self.grid_size-1-1)\n",
    "        self.forbidden_position = {tuple(self.button1_pos)}    \n",
    "\n",
    "        self.max_cycles = 100\n",
    "        self.current_cycles = 0\n",
    "        ######## Pygame graphic configuration \n",
    "        self.window_size = 810\n",
    "        self.cell_size = self.window_size // self.grid_size\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "        \n",
    "        # Walls\n",
    "        self.grid_map = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.grid_map[0, :] = 1\n",
    "        self.grid_map[:, 0] = 1\n",
    "        self.grid_map[-1, :] = 1\n",
    "        self.grid_map[:, -1] = 1\n",
    "        self.grid_map[ :, 1+3] = 1\n",
    "\n",
    "        # Sprites \n",
    "        self.agent_sprites = {}\n",
    "        self.component_sprites = {}\n",
    "\n",
    "        ######## Action space and observation space\n",
    "        # Five possible actions in each grid: stay(0), up(1), down(2), left(3), right(4)\n",
    "        self.action_spaces = {a: spaces.Discrete(5) for a in self.possible_agents}\n",
    "        OBSERVATION_DIM = 2*(len(self.agents)-1)+3*2+1\n",
    "        self.SENTINEL = (self.grid_size-1)*2\n",
    "        self.observation_spaces = {\n",
    "            a: spaces.Box(low=-(self.grid_size-1), high=self.SENTINEL, shape=(OBSERVATION_DIM,), dtype=np.float32) \n",
    "            for a in self.possible_agents\n",
    "        }\n",
    "        self.state_spaces = {a: None for a in self.possible_agents}\n",
    "    \n",
    "    def _visible(self, my_pos, target_pos):\n",
    "        \"\"\"(Manhattan distance).\"\"\"\n",
    "        delta = target_pos - my_pos\n",
    "        is_visible = np.linalg.norm(delta, ord=1) <= self.vision_radius\n",
    "        return (is_visible, delta if is_visible else np.array([self.SENTINEL,self.SENTINEL], dtype=np.float32))\n",
    "\n",
    "    def state(self):\n",
    "        observations = self.gather_observations()\n",
    "        global_state = []\n",
    "        \n",
    "        for agent in self.possible_agents:\n",
    "            if agent in observations:\n",
    "                global_state.append(observations[agent])\n",
    "            else:\n",
    "                # Se l'agente Ã¨ morto/uscito, usa zeri\n",
    "                dim = self.observation_spaces[agent].shape[0]\n",
    "                global_state.append(np.zeros(dim, dtype=np.float32))\n",
    "                \n",
    "        return np.concatenate(global_state)\n",
    "\n",
    "    # Boilerplate PettingZoo\n",
    "    def observation_space(self, agent): return self.observation_spaces[agent]\n",
    "    def action_space(self, agent): return self.action_spaces[agent]\n",
    "\n",
    "    '''\n",
    "    Step in the environment\n",
    "    '''\n",
    "    def step(self, actions):\n",
    "        if not self.agents: return {}, {}, {}, {}, {}\n",
    "        self.current_cycles += 1\n",
    "        \n",
    "        rewards = {a: 0 for a in self.agents}\n",
    "\n",
    "        terminations = {a: False for a in self.agents}\n",
    "        truncations = {a: False for a in self.agents}\n",
    "        infos = {a: {\"is_success\":False} for a in self.agents}\n",
    "        \n",
    "        desired_positions = {}      \n",
    "        button_pressed = False\n",
    "        agents_desire_gate = []\n",
    "        for agent, action in actions.items():\n",
    "            current_pos = self.agent_positions[agent].copy()\n",
    "            target_pos = current_pos.copy()\n",
    "\n",
    "            if action == 1: target_pos[1] -= 1 \n",
    "            elif action == 2: target_pos[1] += 1\n",
    "            elif action == 3: target_pos[0] -= 1\n",
    "            elif action == 4: target_pos[0] += 1\n",
    "\n",
    "            # Monitor button, gate and walls\n",
    "            is_wall = self.grid_map[target_pos[0], target_pos[1]] == 1\n",
    "            is_gate = (target_pos == self.gate_pos).all()\n",
    "            is_button = (target_pos == self.button1_pos).all() or (target_pos == self.button2_pos).all()\n",
    "\n",
    "            if is_button:\n",
    "                button_pressed = True\n",
    "            if is_gate:\n",
    "                agents_desire_gate.append((agent, current_pos))\n",
    "            \n",
    "            if is_wall and not is_gate:\n",
    "                desired_positions[agent] = current_pos \n",
    "            else:\n",
    "                desired_positions[agent] = target_pos\n",
    "                        \n",
    "        # If gate was open remove a wall, if gate was closed update the position of those who wanted to cross it\n",
    "        self.gate_open = button_pressed\n",
    "        pushed_agent = None\n",
    "\n",
    "        if self.gate_open:\n",
    "            self.grid_map[self.gate_pos[0], self.gate_pos[1]] = 0\n",
    "        else:            \n",
    "            self.grid_map[self.gate_pos[0], self.gate_pos[1]] = 1\n",
    "\n",
    "            for a in agents_desire_gate:\n",
    "                agent = a[0]\n",
    "                current_pos = a[1]\n",
    "                desired_positions[agent] = current_pos      # if current pos is not the gate pos\n",
    "\n",
    "                if (current_pos==self.gate_pos).all():      # if current pos is gate pos, in this case agent needs to be pushed down\n",
    "                    gate_x, gate_y = self.gate_pos\n",
    "                    candidate_cells = [\n",
    "                        np.array([gate_x,     gate_y + 1]),\n",
    "                        np.array([gate_x - 1, gate_y + 1]),\n",
    "                        np.array([gate_x + 1, gate_y + 1]),\n",
    "                    ]\n",
    "\n",
    "                    for cell in candidate_cells:\n",
    "                        if not any((cell == p).all() for p in self.agent_positions.values()):\n",
    "                            desired_positions[agent] = cell\n",
    "                            pushed_agent = (agent, cell)\n",
    "                            break\n",
    "                    # Note: if there is not a free cell the agent stays in the gate pos (should not happen)\n",
    "                  \n",
    "        # Check for conflicts (more than one agents have the same desired position)\n",
    "        final_positions = self.agent_positions.copy()\n",
    "        target_counts = defaultdict(list)         # Key: tuple(x, y) of desired positions, Value: list of agents desiring it\n",
    "        for agent, pos in desired_positions.items():\n",
    "            pos_tuple = tuple(pos)\n",
    "            target_counts[pos_tuple].append(agent)\n",
    "\n",
    "        # Solve eventual conflicts\n",
    "        for pos_tuple, agents_at_target in target_counts.items():      \n",
    "            # Case 1: no contended position\n",
    "            if len(agents_at_target) == 1:\n",
    "                agent = agents_at_target[0]\n",
    "                final_positions[agent] = desired_positions[agent]\n",
    "            \n",
    "            # Case 2: contended position\n",
    "            else:\n",
    "                if pushed_agent and tuple(pushed_agent[1]) == pos_tuple:\n",
    "                    winning_agent = pushed_agent[0]\n",
    "                else:\n",
    "                    one_agent_already_here_not_moving = None\n",
    "                    for agent in agents_at_target:\n",
    "                        if tuple(self.agent_positions[agent]) == pos_tuple:\n",
    "                            one_agent_already_here_not_moving = agent\n",
    "                            break\n",
    "\n",
    "                    winning_agent = one_agent_already_here_not_moving if one_agent_already_here_not_moving else random.choice(agents_at_target)\n",
    "                \n",
    "                final_positions[winning_agent] = desired_positions[winning_agent]\n",
    "                agents_at_target.remove(winning_agent)\n",
    "                for losing_agent in agents_at_target[:]:\n",
    "                    final_positions[losing_agent] = self.agent_positions[losing_agent] \n",
    "        self.agent_positions = final_positions\n",
    "\n",
    "        # Negative reward if an agent is on the bottom area and is not pressing the button\n",
    "        agents_upper_area = 0\n",
    "        for a, pos in self.agent_positions.items():\n",
    "            dist_target = np.linalg.norm(pos - self.target_final_pos)\n",
    "            if pos[1]<4:                                # Agent on upper area\n",
    "                rewards[a] = +0.5\n",
    "                agents_upper_area+=1\n",
    "\n",
    "                if (pos == self.button2_pos).all():\n",
    "                    rewards[a] +=0.3\n",
    "            else:\n",
    "                rewards[a] -= (dist_target * 0.05)      # Agent on bottom area\n",
    "\n",
    "                if (pos == self.button1_pos).all():     # Agent on button\n",
    "                    rewards[a] += 0.3     \n",
    "       \n",
    "        if agents_upper_area == len(self.agents):\n",
    "            rewards = {a: +100 for a in self.agents}\n",
    "            terminations = {a: True for a in self.agents}\n",
    "            infos = {a: {\"is_success\":True} for a in self.agents}\n",
    "\n",
    "        if self.current_cycles >= self.max_cycles:\n",
    "            truncations= {a: True for a in self.agents}\n",
    "            \n",
    "        \n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "            \n",
    "        final_obs = self.gather_observations()\n",
    "        self.agents = [a for a in self.agents if not terminations[a]]\n",
    "        return final_obs, rewards, terminations, truncations, infos\n",
    "   \n",
    "    '''\n",
    "    Determines initial condition of the simulation\n",
    "    '''\n",
    "\n",
    "    def generate_valid_position(self):\n",
    "        while True:\n",
    "            x = np.random.randint(self.x_range[0], self.x_range[1])\n",
    "            y = np.random.randint(self.y_range[0], self.y_range[1])\n",
    "            new_position = tuple((x, y))\n",
    "\n",
    "            if new_position not in self.forbidden_position:\n",
    "                return new_position\n",
    "            \n",
    "    def generate_set_initial_positions(self):\n",
    "        set_initial_positions = set()\n",
    "        while len(set_initial_positions)<len(self.possible_agents):\n",
    "            new_pos = self.generate_valid_position()\n",
    "            set_initial_positions.add(new_pos)\n",
    "        return set_initial_positions\n",
    "    \n",
    "    def generate_test_values(self, agent_num):\n",
    "        if agent_num==1:\n",
    "            return[7, 9]\n",
    "        else:\n",
    "            return [9,13]\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.agents = self.possible_agents[:]\n",
    "        set_initial_positions = list(self.generate_set_initial_positions())\n",
    "        self.current_cycles = 0\n",
    "\n",
    "        self.agent_positions = {}\n",
    "        for i, agent_id in enumerate(self.agents):\n",
    "            self.agent_positions[agent_id] = np.array(set_initial_positions[i])\n",
    "        \n",
    "        # To visualize the reset position if \"human\" mode on\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()         \n",
    "\n",
    "        return self.gather_observations(), {a: {} for a in self.agents}\n",
    "    \n",
    "    '''\n",
    "    Observation: [my_cur_pos, (other_cur) x number of other agents, button_pos, gate_pos, gate_open (1|0)]    '''\n",
    "    def gather_observations(self):\n",
    "        gate_status_info = np.array([int(self.gate_open)], dtype=np.float32)\n",
    "        observations = {}\n",
    "        for observing_agent in self.agents:\n",
    "            obs_segments = []\n",
    "            observing_agent_pos = self.agent_positions[observing_agent]\n",
    "            \n",
    "            for other_agent in self.agents:\n",
    "                if other_agent != observing_agent:\n",
    "                    is_visible, delta = self._visible(observing_agent_pos,self.agent_positions[other_agent])\n",
    "                    obs_segments.append(delta)\n",
    "          \n",
    "            is_visible, delta = self._visible(observing_agent_pos,self.button1_pos)\n",
    "            obs_segments.append(delta)\n",
    "           \n",
    "            is_visible, delta = self._visible(observing_agent_pos,self.button2_pos)\n",
    "            obs_segments.append(delta)\n",
    "\n",
    "            is_visible, delta = self._visible(observing_agent_pos,self.gate_pos)\n",
    "            obs_segments.append(delta)\n",
    "\n",
    "            obs_segments.append(gate_status_info if is_visible else np.array([-1], dtype=np.float32))\n",
    "            observations[observing_agent] = np.concatenate(obs_segments, dtype=np.float32)\n",
    "        return observations\n",
    "\n",
    "    '''\n",
    "    Functions for Sprite rendering and loading\n",
    "    '''    \n",
    "    def _create_missing_sprite(self, text, bg_color, border_color = (0,0,0)):  \n",
    "        error_sprite = pygame.Surface((self.cell_size, self.cell_size), pygame.SRCALPHA)\n",
    "        error_sprite.fill((0, 0, 0, 0))\n",
    "        center = (self.cell_size // 2, self.cell_size // 2)\n",
    "        radius = int(self.cell_size * 0.4)\n",
    "        pygame.draw.circle(error_sprite, bg_color, center, radius) \n",
    "        pygame.draw.circle(error_sprite, border_color, center, radius, 2)\n",
    "        \n",
    "        # Add text label\n",
    "        try:\n",
    "            font_size = int(self.cell_size * 0.22)\n",
    "            font = pygame.font.Font(None, font_size)   \n",
    "            text_color = (0, 0, 0) if sum(bg_color) > 300 else (255, 255, 255) \n",
    "            text_surface = font.render(text, True, text_color)\n",
    "            text_rect = text_surface.get_rect(center=center)\n",
    "            error_sprite.blit(text_surface, text_rect)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"WARNING: Error while writing text inside missing sprite {text}. A missing sprite without text label will be used for this simulation.\")\n",
    "            pass\n",
    "            \n",
    "        return error_sprite\n",
    "    \n",
    "    def _load_and_scale_sprite(self, filename, component_name):\n",
    "        path = os.path.join(SPRITES_DIR, filename)\n",
    "    \n",
    "        try:\n",
    "            image = pygame.image.load(path).convert_alpha() \n",
    "            scaled_size = int(self.cell_size )\n",
    "            return pygame.transform.scale(image, (scaled_size, scaled_size))\n",
    "            \n",
    "        except (FileNotFoundError, pygame.error) as e:\n",
    "            print(f\"WARNING! Sprite image {path} not found. Using default sprite for this simulation.\")\n",
    "    \n",
    "            text = component_name.upper() if component_name else \"ERROR\"\n",
    "            bg_color = (100, 100, 255) if \"AGENT\" in text else (128,128,128) # Blue agent, Gray fixed components\n",
    "            return self._create_missing_sprite(text, bg_color)\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode is None:\n",
    "            return\n",
    "\n",
    "        if self.window is None:\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            pygame.font.init()\n",
    "            self.window = pygame.display.set_mode((self.window_size, self.window_size))\n",
    "            \n",
    "            for agent_name in self.agents:\n",
    "               # self.agent_sprites[agent_name] = self._load_and_scale_sprite(f\"{agent_name}.png\", agent_name)\n",
    "               self.agent_sprites[agent_name] = self._load_and_scale_sprite(\".png\", agent_name)\n",
    "\n",
    "            for name, data in self.fixed_components.items():\n",
    "                self.component_sprites[name] = self._load_and_scale_sprite(data[\"file\"], name)\n",
    "\n",
    "                 \n",
    "        if self.clock is None:\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
    "        canvas.fill((220, 220, 220)) \n",
    "        pix_square_size = self.cell_size \n",
    "        sprite_offset = (pix_square_size - int(pix_square_size * 0.8)) // 2\n",
    "\n",
    "        # Render walls\n",
    "        for x in range(self.grid_size):\n",
    "            for y in range(self.grid_size):\n",
    "                if self.grid_map[x, y] == 1:\n",
    "                    pygame.draw.rect(\n",
    "                        canvas, \n",
    "                        (50, 50, 50),\n",
    "                        pygame.Rect(x * pix_square_size, y * pix_square_size, pix_square_size, pix_square_size)\n",
    "                    )\n",
    "\n",
    "        # Render fixed components and agents\n",
    "        for name, data in self.fixed_components.items():\n",
    "            if self.gate_open and name == \"gate_close\":\n",
    "                continue\n",
    "            pos = data[\"pos\"]\n",
    "            x_coord = pos[0] * pix_square_size + sprite_offset\n",
    "            y_coord = pos[1] * pix_square_size + sprite_offset\n",
    "            sprite = self.component_sprites[name]\n",
    "            canvas.blit(sprite, (x_coord, y_coord))\n",
    "\n",
    "        for agent in self.agents:\n",
    "            pos = self.agent_positions[agent]            \n",
    "            x_coord = pos[0] * pix_square_size + sprite_offset\n",
    "            y_coord = pos[1] * pix_square_size + sprite_offset\n",
    "            \n",
    "            sprite = self.agent_sprites[agent]\n",
    "            canvas.blit(sprite, (x_coord, y_coord))\n",
    "\n",
    "        # Render the grid\n",
    "        for x in range(self.grid_size + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas, 0, (0, pix_square_size * x), (self.window_size, pix_square_size * x), width=2\n",
    "            )\n",
    "            pygame.draw.line(\n",
    "                canvas, 0, (pix_square_size * x, 0), (pix_square_size * x, self.window_size), width=2\n",
    "            )\n",
    "\n",
    "        # Display the render\n",
    "        self.window.blit(canvas, canvas.get_rect())\n",
    "        pygame.event.pump()\n",
    "        pygame.display.update()\n",
    "        self.clock.tick(4) # FPS\n",
    "\n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95118daf",
   "metadata": {},
   "source": [
    "**Wrap the envornment in a PettingZoo env (for compatibility with Ray) and register it on Ray lib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5fd6c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.env.wrappers.pettingzoo_env import ParallelPettingZooEnv\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "def env_creator(config):\n",
    "    return ParallelPettingZooEnv(\n",
    "        MyGridWorld(render_mode=None, n_agents=2)\n",
    "    )\n",
    "\n",
    "register_env(\"my_gridworld\", env_creator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1cc4a4",
   "metadata": {},
   "source": [
    "## **IPPO - loose play settings**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f0dc4f",
   "metadata": {},
   "source": [
    "Callback to register episode success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f520adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "\n",
    "class SuccessMetricCallback(DefaultCallbacks):\n",
    "    def on_episode_end(self, *, worker, base_env, policies, episode, **kwargs):\n",
    "        \n",
    "        is_success = False\n",
    "        one_agent_id = list(episode.get_agents())[-1]\n",
    "        last_info = episode.last_info_for(one_agent_id)\n",
    "        is_success = last_info[\"is_success\"]\n",
    "       \n",
    "        episode.custom_metrics[\"success_rate\"] = int(is_success)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297e0795",
   "metadata": {},
   "source": [
    "New config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b0f5b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "dummy_env = MyGridWorld(n_agents=2)\n",
    "agent_ids = dummy_env.possible_agents\n",
    "\n",
    "multi_agent_policies = {\n",
    "    agent_id: (\n",
    "        None,  # default model\n",
    "        dummy_env.observation_spaces[agent_id],\n",
    "        dummy_env.action_spaces[agent_id],\n",
    "        {\n",
    "            \"model\": {\n",
    "                \"use_lstm\": True,\n",
    "                \"lstm_cell_size\": 128,\n",
    "                \"max_seq_len\": 100,\n",
    "                \"lstm_use_prev_action\": True,\n",
    "                \"lstm_use_prev_reward\": True,\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    for agent_id in agent_ids\n",
    "}\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=\"my_gridworld\")\n",
    "    .env_runners(num_env_runners=0)\n",
    "    .callbacks(callbacks_class=SuccessMetricCallback)\n",
    "    .multi_agent(\n",
    "        policies=multi_agent_policies,\n",
    "        policy_mapping_fn=lambda agent_id, *args, **kwargs: agent_id\n",
    "    )\n",
    "    .api_stack(\n",
    "        enable_rl_module_and_learner=False,\n",
    "        enable_env_runner_and_connector_v2=False\n",
    "    )\n",
    "    .evaluation(\n",
    "        evaluation_interval=1,\n",
    "        evaluation_duration=10,\n",
    "        evaluation_duration_unit=\"episodes\",\n",
    "        evaluation_num_env_runners=1,\n",
    "        evaluation_config={\"explore\": True}\n",
    "    )\n",
    "    .training(\n",
    "        lr = 1e-4,\n",
    "        train_batch_size_per_learner=8000,\n",
    "        num_epochs=10,\n",
    "        entropy_coeff=0.01,\n",
    "        entropy_coeff_schedule = [\n",
    "            [0, 0.03],\n",
    "            [2e6, 0.005]\n",
    "        ],\n",
    "        kl_coeff=0.2,\n",
    "        kl_target=0.01,\n",
    "    )\n",
    ")\n",
    "\n",
    "dummy_env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a893cb",
   "metadata": {},
   "source": [
    "Old config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e357c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "dummy_env = MyGridWorld(n_agents=2)\n",
    "agent_ids = dummy_env.possible_agents\n",
    "\n",
    "multi_agent_policies = {\n",
    "    agent_id: (\n",
    "        None,  # default model\n",
    "        dummy_env.observation_spaces[agent_id],\n",
    "        dummy_env.action_spaces[agent_id],\n",
    "        {\n",
    "            \"model\": {\n",
    "                \"use_lstm\": True,\n",
    "                \"lstm_cell_size\": 128,\n",
    "                \"max_seq_len\": 75,\n",
    "                \"lstm_use_prev_action\": True,\n",
    "                \"lstm_use_prev_reward\": True,\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    for agent_id in agent_ids\n",
    "}\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=\"my_gridworld\")\n",
    "    .env_runners(num_env_runners=0)\n",
    "    .callbacks(callbacks_class=SuccessMetricCallback)\n",
    "    .multi_agent(\n",
    "        policies=multi_agent_policies,\n",
    "        policy_mapping_fn=lambda agent_id, *args, **kwargs: agent_id\n",
    "    )\n",
    "    .api_stack(\n",
    "        enable_rl_module_and_learner=False,\n",
    "        enable_env_runner_and_connector_v2=False\n",
    "    )\n",
    "    .evaluation(\n",
    "        evaluation_interval=1,\n",
    "        evaluation_duration=10,\n",
    "        evaluation_duration_unit=\"episodes\",\n",
    "        evaluation_num_env_runners=1,\n",
    "        evaluation_config={\"explore\": True}\n",
    "    )\n",
    "    .training(\n",
    "        lr = 1e-4,\n",
    "        train_batch_size_per_learner=4000,\n",
    "        num_epochs=10,\n",
    "        entropy_coeff=0.03,\n",
    "        \n",
    "        kl_coeff=0.2,\n",
    "        kl_target=0.01,\n",
    "    )\n",
    ")\n",
    "\n",
    "dummy_env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bc5eb9",
   "metadata": {},
   "source": [
    "## **Save the agents model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02efe300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save_model(ppo, file_name):\n",
    "    current_dir = os.getcwd()\n",
    "    model_dir = os.path.join(current_dir, \"models\")\n",
    "    checkpoint_name = os.path.join(model_dir, file_name)\n",
    "    ppo.save(checkpoint_name)\n",
    "\n",
    "    print(f\"Model saved into {checkpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ad7bb",
   "metadata": {},
   "source": [
    "## **Wandb, 3 runs of training to generate esteme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae4f79cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "RUN NUMBER 2/3\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:527: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "2026-01-02 22:03:37,577\tINFO worker.py:2007 -- Started a local Ray instance.\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/_private/worker.py:2046: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "2026-01-02 22:03:40,356\tWARNING recurrent_net.py:85 -- DeprecationWarning: `ray.rllib.models.torch.recurrent_net.RecurrentNetwork` has been deprecated. This will raise an error in the future!\n",
      "[2026-01-02 22:03:40,538 E 302279 302279] core_worker.cc:2223: Actor with class name: 'RolloutWorker' and ID: 'd8b5367ca80da5c0b1739e0401000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(RolloutWorker pid=302496)\u001b[0m /home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "\u001b[36m(RolloutWorker pid=302496)\u001b[0m   from pkg_resources import resource_stream, resource_exists\n",
      "\u001b[36m(RolloutWorker pid=302496)\u001b[0m DeprecationWarning: `ray.rllib.models.torch.recurrent_net.RecurrentNetwork` has been deprecated. This will raise an error in the future!\n",
      "2026-01-02 22:03:44,722\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m299011\u001b[0m (\u001b[33m299011-unimore\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/terra/Desktop/magistrale/distributed_ai_project/src/policies/PPO/env_7_pomdp/wandb/run-20260102_220345-7xyvbevn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents/runs/7xyvbevn' target=\"_blank\">run_2</a></strong> to <a href='https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents/runs/7xyvbevn' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents/runs/7xyvbevn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=gcs_server)\u001b[0m [2026-01-02 22:04:06,529 E 302326 302326] (gcs_server) gcs_server.cc:303: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[33m(raylet)\u001b[0m [2026-01-02 22:04:07,515 E 302441 302441] (raylet) main.cc:1032: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[36m(RolloutWorker pid=302496)\u001b[0m [2026-01-02 22:04:08,354 E 302496 302612] core_worker_process.cc:842: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "[2026-01-02 22:04:08,740 E 302279 302494] core_worker_process.cc:842: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "2026-01-02 22:04:27,235\tWARNING sgd.py:55 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------ITERATION 0, num episode 80-------------------------------------\n",
      "TRAINING\n",
      "Rew:-76.76 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-58.41 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 1, num episode 160------------------------------------\n",
      "TRAINING\n",
      "Rew:-65.61 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-47.68 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 2, num episode 240------------------------------------\n",
      "TRAINING\n",
      "Rew:-49.72 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-39.89 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 3, num episode 320------------------------------------\n",
      "TRAINING\n",
      "Rew:-45.34 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-40.55 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 4, num episode 400------------------------------------\n",
      "TRAINING\n",
      "Rew:-36.09 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-39.27 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 5, num episode 480------------------------------------\n",
      "TRAINING\n",
      "Rew:-33.67 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-27.03 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 6, num episode 560------------------------------------\n",
      "TRAINING\n",
      "Rew:-27.22 \n",
      "Steps per episode:99.93 \n",
      "Success rate:1.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-31.59 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 7, num episode 640------------------------------------\n",
      "TRAINING\n",
      "Rew:-24.02 \n",
      "Steps per episode:99.83 \n",
      "Success rate:2.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-24.4 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 8, num episode 720------------------------------------\n",
      "TRAINING\n",
      "Rew:-25.86 \n",
      "Steps per episode:99.96 \n",
      "Success rate:1.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-22.91 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 9, num episode 800------------------------------------\n",
      "TRAINING\n",
      "Rew:-27.0 \n",
      "Steps per episode:99.85 \n",
      "Success rate:1.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-33.96 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 10, num episode 881------------------------------------\n",
      "TRAINING\n",
      "Rew:-17.02 \n",
      "Steps per episode:99.12 \n",
      "Success rate:4.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-28.02 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 11, num episode 961------------------------------------\n",
      "TRAINING\n",
      "Rew:-24.13 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-31.43 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 12, num episode 1041-----------------------------------\n",
      "TRAINING\n",
      "Rew:-24.49 \n",
      "Steps per episode:99.67 \n",
      "Success rate:1.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-20.77 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 13, num episode 1121-----------------------------------\n",
      "TRAINING\n",
      "Rew:-23.31 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-28.42 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 14, num episode 1201-----------------------------------\n",
      "TRAINING\n",
      "Rew:-21.88 \n",
      "Steps per episode:99.44 \n",
      "Success rate:1.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-16.81 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 15, num episode 1283-----------------------------------\n",
      "TRAINING\n",
      "Rew:-13.28 \n",
      "Steps per episode:98.24 \n",
      "Success rate:5.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-23.85 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 16, num episode 1364-----------------------------------\n",
      "TRAINING\n",
      "Rew:-12.88 \n",
      "Steps per episode:98.32 \n",
      "Success rate:5.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-23.02 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 17, num episode 1444-----------------------------------\n",
      "TRAINING\n",
      "Rew:-22.3 \n",
      "Steps per episode:99.81 \n",
      "Success rate:1.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-10.3 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 18, num episode 1525-----------------------------------\n",
      "TRAINING\n",
      "Rew:-17.75 \n",
      "Steps per episode:99.52 \n",
      "Success rate:2.0%\n",
      "\n",
      "TESTING\n",
      "Rew:0.23 \n",
      "Steps per episode:98.22 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 19, num episode 1605-----------------------------------\n",
      "TRAINING\n",
      "Rew:-20.0 \n",
      "Steps per episode:99.55 \n",
      "Success rate:1.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-15.25 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 20, num episode 1686-----------------------------------\n",
      "TRAINING\n",
      "Rew:-18.01 \n",
      "Steps per episode:99.11 \n",
      "Success rate:2.0%\n",
      "\n",
      "TESTING\n",
      "Rew:17.75 \n",
      "Steps per episode:88.78 \n",
      "Success rate:22.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 21, num episode 1767-----------------------------------\n",
      "TRAINING\n",
      "Rew:-13.01 \n",
      "Steps per episode:98.54 \n",
      "Success rate:4.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-6.0 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 22, num episode 1848-----------------------------------\n",
      "TRAINING\n",
      "Rew:-14.27 \n",
      "Steps per episode:99.51 \n",
      "Success rate:2.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-4.55 \n",
      "Steps per episode:99.0 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 23, num episode 1928-----------------------------------\n",
      "TRAINING\n",
      "Rew:-12.81 \n",
      "Steps per episode:99.48 \n",
      "Success rate:2.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-6.76 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 24, num episode 2010-----------------------------------\n",
      "TRAINING\n",
      "Rew:-1.51 \n",
      "Steps per episode:97.4 \n",
      "Success rate:7.000000000000001%\n",
      "\n",
      "TESTING\n",
      "Rew:-22.93 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 25, num episode 2091-----------------------------------\n",
      "TRAINING\n",
      "Rew:-5.38 \n",
      "Steps per episode:98.37 \n",
      "Success rate:5.0%\n",
      "\n",
      "TESTING\n",
      "Rew:0.35 \n",
      "Steps per episode:95.44 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 26, num episode 2173-----------------------------------\n",
      "TRAINING\n",
      "Rew:2.4 \n",
      "Steps per episode:97.22 \n",
      "Success rate:9.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-3.84 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 27, num episode 2255-----------------------------------\n",
      "TRAINING\n",
      "Rew:-0.22 \n",
      "Steps per episode:97.81 \n",
      "Success rate:6.0%\n",
      "\n",
      "TESTING\n",
      "Rew:32.7 \n",
      "Steps per episode:90.67 \n",
      "Success rate:22.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 28, num episode 2336-----------------------------------\n",
      "TRAINING\n",
      "Rew:0.64 \n",
      "Steps per episode:98.63 \n",
      "Success rate:6.0%\n",
      "\n",
      "TESTING\n",
      "Rew:9.25 \n",
      "Steps per episode:99.11 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 29, num episode 2419-----------------------------------\n",
      "TRAINING\n",
      "Rew:4.39 \n",
      "Steps per episode:97.22 \n",
      "Success rate:9.0%\n",
      "\n",
      "TESTING\n",
      "Rew:11.89 \n",
      "Steps per episode:97.44 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 30, num episode 2500-----------------------------------\n",
      "TRAINING\n",
      "Rew:-0.65 \n",
      "Steps per episode:98.36 \n",
      "Success rate:6.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-9.11 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 31, num episode 2582-----------------------------------\n",
      "TRAINING\n",
      "Rew:8.34 \n",
      "Steps per episode:97.36 \n",
      "Success rate:8.0%\n",
      "\n",
      "TESTING\n",
      "Rew:37.79 \n",
      "Steps per episode:92.67 \n",
      "Success rate:22.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 32, num episode 2665-----------------------------------\n",
      "TRAINING\n",
      "Rew:9.89 \n",
      "Steps per episode:96.2 \n",
      "Success rate:11.0%\n",
      "\n",
      "TESTING\n",
      "Rew:16.71 \n",
      "Steps per episode:94.67 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 33, num episode 2746-----------------------------------\n",
      "TRAINING\n",
      "Rew:4.96 \n",
      "Steps per episode:97.7 \n",
      "Success rate:7.000000000000001%\n",
      "\n",
      "TESTING\n",
      "Rew:-7.84 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 34, num episode 2828-----------------------------------\n",
      "TRAINING\n",
      "Rew:-0.66 \n",
      "Steps per episode:97.75 \n",
      "Success rate:5.0%\n",
      "\n",
      "TESTING\n",
      "Rew:36.38 \n",
      "Steps per episode:94.78 \n",
      "Success rate:22.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 35, num episode 2910-----------------------------------\n",
      "TRAINING\n",
      "Rew:1.21 \n",
      "Steps per episode:98.12 \n",
      "Success rate:7.000000000000001%\n",
      "\n",
      "TESTING\n",
      "Rew:-6.84 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 36, num episode 2993-----------------------------------\n",
      "TRAINING\n",
      "Rew:12.44 \n",
      "Steps per episode:96.43 \n",
      "Success rate:11.0%\n",
      "\n",
      "TESTING\n",
      "Rew:1.37 \n",
      "Steps per episode:95.0 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 37, num episode 3077-----------------------------------\n",
      "TRAINING\n",
      "Rew:17.8 \n",
      "Steps per episode:95.93 \n",
      "Success rate:13.0%\n",
      "\n",
      "TESTING\n",
      "Rew:28.3 \n",
      "Steps per episode:94.33 \n",
      "Success rate:22.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 38, num episode 3162-----------------------------------\n",
      "TRAINING\n",
      "Rew:23.66 \n",
      "Steps per episode:93.99 \n",
      "Success rate:16.0%\n",
      "\n",
      "TESTING\n",
      "Rew:20.81 \n",
      "Steps per episode:99.22 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 39, num episode 3249-----------------------------------\n",
      "TRAINING\n",
      "Rew:27.22 \n",
      "Steps per episode:91.94 \n",
      "Success rate:18.0%\n",
      "\n",
      "TESTING\n",
      "Rew:43.87 \n",
      "Steps per episode:95.0 \n",
      "Success rate:22.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 40, num episode 3332-----------------------------------\n",
      "TRAINING\n",
      "Rew:20.69 \n",
      "Steps per episode:95.62 \n",
      "Success rate:14.000000000000002%\n",
      "\n",
      "TESTING\n",
      "Rew:59.56 \n",
      "Steps per episode:86.33 \n",
      "Success rate:33.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 41, num episode 3419-----------------------------------\n",
      "TRAINING\n",
      "Rew:50.19 \n",
      "Steps per episode:92.89 \n",
      "Success rate:28.000000000000004%\n",
      "\n",
      "TESTING\n",
      "Rew:9.4 \n",
      "Steps per episode:94.78 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 42, num episode 3507-----------------------------------\n",
      "TRAINING\n",
      "Rew:36.45 \n",
      "Steps per episode:92.36 \n",
      "Success rate:21.0%\n",
      "\n",
      "TESTING\n",
      "Rew:14.62 \n",
      "Steps per episode:92.0 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 43, num episode 3597-----------------------------------\n",
      "TRAINING\n",
      "Rew:52.3 \n",
      "Steps per episode:89.59 \n",
      "Success rate:28.000000000000004%\n",
      "\n",
      "TESTING\n",
      "Rew:32.33 \n",
      "Steps per episode:97.67 \n",
      "Success rate:22.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 44, num episode 3681-----------------------------------\n",
      "TRAINING\n",
      "Rew:35.4 \n",
      "Steps per episode:94.45 \n",
      "Success rate:21.0%\n",
      "\n",
      "TESTING\n",
      "Rew:35.14 \n",
      "Steps per episode:92.22 \n",
      "Success rate:22.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 45, num episode 3769-----------------------------------\n",
      "TRAINING\n",
      "Rew:57.77 \n",
      "Steps per episode:91.06 \n",
      "Success rate:28.999999999999996%\n",
      "\n",
      "TESTING\n",
      "Rew:86.64 \n",
      "Steps per episode:86.78 \n",
      "Success rate:44.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 46, num episode 3858-----------------------------------\n",
      "TRAINING\n",
      "Rew:58.4 \n",
      "Steps per episode:90.36 \n",
      "Success rate:28.000000000000004%\n",
      "\n",
      "TESTING\n",
      "Rew:10.13 \n",
      "Steps per episode:92.67 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 47, num episode 3948-----------------------------------\n",
      "TRAINING\n",
      "Rew:52.75 \n",
      "Steps per episode:88.73 \n",
      "Success rate:27.0%\n",
      "\n",
      "TESTING\n",
      "Rew:92.72 \n",
      "Steps per episode:75.22 \n",
      "Success rate:44.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 48, num episode 4039-----------------------------------\n",
      "TRAINING\n",
      "Rew:71.57 \n",
      "Steps per episode:87.01 \n",
      "Success rate:35.0%\n",
      "\n",
      "TESTING\n",
      "Rew:59.06 \n",
      "Steps per episode:80.22 \n",
      "Success rate:33.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 49, num episode 4131-----------------------------------\n",
      "TRAINING\n",
      "Rew:60.35 \n",
      "Steps per episode:86.67 \n",
      "Success rate:31.0%\n",
      "\n",
      "TESTING\n",
      "Rew:69.34 \n",
      "Steps per episode:81.56 \n",
      "Success rate:33.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 50, num episode 4227-----------------------------------\n",
      "TRAINING\n",
      "Rew:82.01 \n",
      "Steps per episode:83.58 \n",
      "Success rate:40.0%\n",
      "\n",
      "TESTING\n",
      "Rew:107.92 \n",
      "Steps per episode:82.67 \n",
      "Success rate:56.00000000000001%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 51, num episode 4326-----------------------------------\n",
      "TRAINING\n",
      "Rew:93.39 \n",
      "Steps per episode:80.6 \n",
      "Success rate:47.0%\n",
      "\n",
      "TESTING\n",
      "Rew:105.22 \n",
      "Steps per episode:75.22 \n",
      "Success rate:56.00000000000001%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 52, num episode 4428-----------------------------------\n",
      "TRAINING\n",
      "Rew:102.78 \n",
      "Steps per episode:78.01 \n",
      "Success rate:52.0%\n",
      "\n",
      "TESTING\n",
      "Rew:74.67 \n",
      "Steps per episode:87.56 \n",
      "Success rate:33.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 53, num episode 4531-----------------------------------\n",
      "TRAINING\n",
      "Rew:116.21 \n",
      "Steps per episode:78.18 \n",
      "Success rate:56.99999999999999%\n",
      "\n",
      "TESTING\n",
      "Rew:105.01 \n",
      "Steps per episode:75.67 \n",
      "Success rate:56.00000000000001%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 54, num episode 4634-----------------------------------\n",
      "TRAINING\n",
      "Rew:103.87 \n",
      "Steps per episode:77.93 \n",
      "Success rate:50.0%\n",
      "\n",
      "TESTING\n",
      "Rew:88.72 \n",
      "Steps per episode:87.44 \n",
      "Success rate:44.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 55, num episode 4730-----------------------------------\n",
      "TRAINING\n",
      "Rew:90.79 \n",
      "Steps per episode:83.03 \n",
      "Success rate:45.0%\n",
      "\n",
      "TESTING\n",
      "Rew:96.72 \n",
      "Steps per episode:79.11 \n",
      "Success rate:44.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 56, num episode 4833-----------------------------------\n",
      "TRAINING\n",
      "Rew:102.12 \n",
      "Steps per episode:77.37 \n",
      "Success rate:50.0%\n",
      "\n",
      "TESTING\n",
      "Rew:163.88 \n",
      "Steps per episode:73.44 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 57, num episode 4936-----------------------------------\n",
      "TRAINING\n",
      "Rew:110.02 \n",
      "Steps per episode:77.83 \n",
      "Success rate:51.0%\n",
      "\n",
      "TESTING\n",
      "Rew:142.18 \n",
      "Steps per episode:73.44 \n",
      "Success rate:67.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 58, num episode 5052-----------------------------------\n",
      "TRAINING\n",
      "Rew:129.35 \n",
      "Steps per episode:69.16 \n",
      "Success rate:64.0%\n",
      "\n",
      "TESTING\n",
      "Rew:84.92 \n",
      "Steps per episode:83.33 \n",
      "Success rate:44.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 59, num episode 5161-----------------------------------\n",
      "TRAINING\n",
      "Rew:130.15 \n",
      "Steps per episode:73.41 \n",
      "Success rate:62.0%\n",
      "\n",
      "TESTING\n",
      "Rew:133.98 \n",
      "Steps per episode:61.33 \n",
      "Success rate:67.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 60, num episode 5278-----------------------------------\n",
      "TRAINING\n",
      "Rew:142.0 \n",
      "Steps per episode:68.37 \n",
      "Success rate:69.0%\n",
      "\n",
      "TESTING\n",
      "Rew:159.63 \n",
      "Steps per episode:60.56 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 61, num episode 5397-----------------------------------\n",
      "TRAINING\n",
      "Rew:141.45 \n",
      "Steps per episode:67.45 \n",
      "Success rate:69.0%\n",
      "\n",
      "TESTING\n",
      "Rew:160.45 \n",
      "Steps per episode:67.44 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 62, num episode 5519-----------------------------------\n",
      "TRAINING\n",
      "Rew:150.09 \n",
      "Steps per episode:65.52 \n",
      "Success rate:72.0%\n",
      "\n",
      "TESTING\n",
      "Rew:118.81 \n",
      "Steps per episode:69.89 \n",
      "Success rate:56.00000000000001%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 63, num episode 5647-----------------------------------\n",
      "TRAINING\n",
      "Rew:154.41 \n",
      "Steps per episode:61.97 \n",
      "Success rate:75.0%\n",
      "\n",
      "TESTING\n",
      "Rew:151.18 \n",
      "Steps per episode:61.33 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 64, num episode 5768-----------------------------------\n",
      "TRAINING\n",
      "Rew:158.82 \n",
      "Steps per episode:65.93 \n",
      "Success rate:78.0%\n",
      "\n",
      "TESTING\n",
      "Rew:161.15 \n",
      "Steps per episode:56.44 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 65, num episode 5901-----------------------------------\n",
      "TRAINING\n",
      "Rew:145.74 \n",
      "Steps per episode:60.67 \n",
      "Success rate:71.0%\n",
      "\n",
      "TESTING\n",
      "Rew:157.77 \n",
      "Steps per episode:56.78 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 66, num episode 6024-----------------------------------\n",
      "TRAINING\n",
      "Rew:148.83 \n",
      "Steps per episode:64.59 \n",
      "Success rate:72.0%\n",
      "\n",
      "TESTING\n",
      "Rew:183.01 \n",
      "Steps per episode:63.56 \n",
      "Success rate:89.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 67, num episode 6151-----------------------------------\n",
      "TRAINING\n",
      "Rew:153.64 \n",
      "Steps per episode:63.65 \n",
      "Success rate:75.0%\n",
      "\n",
      "TESTING\n",
      "Rew:156.93 \n",
      "Steps per episode:52.89 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 68, num episode 6297-----------------------------------\n",
      "TRAINING\n",
      "Rew:150.18 \n",
      "Steps per episode:54.54 \n",
      "Success rate:75.0%\n",
      "\n",
      "TESTING\n",
      "Rew:161.28 \n",
      "Steps per episode:52.0 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 69, num episode 6451-----------------------------------\n",
      "TRAINING\n",
      "Rew:167.03 \n",
      "Steps per episode:52.06 \n",
      "Success rate:83.0%\n",
      "\n",
      "TESTING\n",
      "Rew:165.07 \n",
      "Steps per episode:66.56 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 70, num episode 6589-----------------------------------\n",
      "TRAINING\n",
      "Rew:167.4 \n",
      "Steps per episode:57.97 \n",
      "Success rate:82.0%\n",
      "\n",
      "TESTING\n",
      "Rew:91.88 \n",
      "Steps per episode:73.33 \n",
      "Success rate:44.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 71, num episode 6736-----------------------------------\n",
      "TRAINING\n",
      "Rew:156.21 \n",
      "Steps per episode:54.41 \n",
      "Success rate:76.0%\n",
      "\n",
      "TESTING\n",
      "Rew:159.71 \n",
      "Steps per episode:59.33 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 72, num episode 6879-----------------------------------\n",
      "TRAINING\n",
      "Rew:168.58 \n",
      "Steps per episode:55.97 \n",
      "Success rate:83.0%\n",
      "\n",
      "TESTING\n",
      "Rew:195.41 \n",
      "Steps per episode:38.78 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 73, num episode 7053-----------------------------------\n",
      "TRAINING\n",
      "Rew:180.26 \n",
      "Steps per episode:45.92 \n",
      "Success rate:90.0%\n",
      "\n",
      "TESTING\n",
      "Rew:200.19 \n",
      "Steps per episode:43.0 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 74, num episode 7211-----------------------------------\n",
      "TRAINING\n",
      "Rew:185.61 \n",
      "Steps per episode:50.22 \n",
      "Success rate:93.0%\n",
      "\n",
      "TESTING\n",
      "Rew:201.91 \n",
      "Steps per episode:45.0 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 75, num episode 7401-----------------------------------\n",
      "TRAINING\n",
      "Rew:193.36 \n",
      "Steps per episode:42.58 \n",
      "Success rate:96.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.27 \n",
      "Steps per episode:34.0 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 76, num episode 7604-----------------------------------\n",
      "TRAINING\n",
      "Rew:193.67 \n",
      "Steps per episode:39.34 \n",
      "Success rate:98.0%\n",
      "\n",
      "TESTING\n",
      "Rew:201.47 \n",
      "Steps per episode:40.11 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 77, num episode 7791-----------------------------------\n",
      "TRAINING\n",
      "Rew:194.47 \n",
      "Steps per episode:42.78 \n",
      "Success rate:97.0%\n",
      "\n",
      "TESTING\n",
      "Rew:201.74 \n",
      "Steps per episode:35.67 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 78, num episode 7991-----------------------------------\n",
      "TRAINING\n",
      "Rew:196.6 \n",
      "Steps per episode:40.05 \n",
      "Success rate:98.0%\n",
      "\n",
      "TESTING\n",
      "Rew:195.92 \n",
      "Steps per episode:35.44 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 79, num episode 8211-----------------------------------\n",
      "TRAINING\n",
      "Rew:192.28 \n",
      "Steps per episode:36.37 \n",
      "Success rate:96.0%\n",
      "\n",
      "TESTING\n",
      "Rew:196.52 \n",
      "Steps per episode:36.22 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "Model saved into /home/terra/Desktop/magistrale/distributed_ai_project/src/policies/PPO/env_7_pomdp/models/looseplay_2agents_densereward_run_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56ba75f4ce34b09a8d9e8beaad40e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Episodes</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Testing_reward_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Testing_steps_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Testing_success_rate_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Training_reward_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Training_steps_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Training_success_rate_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Episodes</td><td>8211</td></tr><tr><td>Testing_reward_per_episode</td><td>196.52</td></tr><tr><td>Testing_steps_per_episode</td><td>36.22</td></tr><tr><td>Testing_success_rate_per_episode</td><td>100.0</td></tr><tr><td>Training_reward_per_episode</td><td>192.28</td></tr><tr><td>Training_steps_per_episode</td><td>36.37</td></tr><tr><td>Training_success_rate_per_episode</td><td>96.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_2</strong> at: <a href='https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents/runs/7xyvbevn' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents/runs/7xyvbevn</a><br/> View project at: <a href='https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260102_220345-7xyvbevn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "RUN NUMBER 3/3\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:527: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=302500)\u001b[0m /home/terra/anaconda3/envs/MARL/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "\u001b[36m(RolloutWorker pid=302500)\u001b[0m   from pkg_resources import resource_stream, resource_exists\n",
      "\u001b[36m(pid=302495)\u001b[0m [2026-01-02 22:04:08,728 E 302495 303041] core_worker_process.cc:842: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\u001b[32m [repeated 11x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=302500)\u001b[0m DeprecationWarning: `ray.rllib.models.torch.recurrent_net.RecurrentNetwork` has been deprecated. This will raise an error in the future!\n",
      "2026-01-02 23:11:15,648\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/terra/Desktop/magistrale/distributed_ai_project/src/policies/PPO/env_7_pomdp/wandb/run-20260102_231115-meo098rm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents/runs/meo098rm' target=\"_blank\">run_3</a></strong> to <a href='https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents/runs/meo098rm' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents/runs/meo098rm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------ITERATION 0, num episode 80-------------------------------------\n",
      "TRAINING\n",
      "Rew:-71.26 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-68.69 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 1, num episode 160------------------------------------\n",
      "TRAINING\n",
      "Rew:-63.02 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-47.98 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 2, num episode 240------------------------------------\n",
      "TRAINING\n",
      "Rew:-53.66 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-40.63 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 3, num episode 320------------------------------------\n",
      "TRAINING\n",
      "Rew:-45.16 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-34.13 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 4, num episode 400------------------------------------\n",
      "TRAINING\n",
      "Rew:-36.14 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-32.4 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 5, num episode 480------------------------------------\n",
      "TRAINING\n",
      "Rew:-38.28 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-27.78 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 6, num episode 560------------------------------------\n",
      "TRAINING\n",
      "Rew:-32.17 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-33.36 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 7, num episode 640------------------------------------\n",
      "TRAINING\n",
      "Rew:-31.18 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-21.09 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 8, num episode 720------------------------------------\n",
      "TRAINING\n",
      "Rew:-28.14 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-28.82 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "------------------------------------ITERATION 9, num episode 800------------------------------------\n",
      "TRAINING\n",
      "Rew:-26.36 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-28.8 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 10, num episode 880------------------------------------\n",
      "TRAINING\n",
      "Rew:-26.97 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-25.42 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 11, num episode 960------------------------------------\n",
      "TRAINING\n",
      "Rew:-25.04 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-28.04 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 12, num episode 1040-----------------------------------\n",
      "TRAINING\n",
      "Rew:-24.41 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-22.97 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 13, num episode 1120-----------------------------------\n",
      "TRAINING\n",
      "Rew:-24.13 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-18.92 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 14, num episode 1200-----------------------------------\n",
      "TRAINING\n",
      "Rew:-21.89 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-21.27 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 15, num episode 1280-----------------------------------\n",
      "TRAINING\n",
      "Rew:-23.42 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-25.85 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 16, num episode 1360-----------------------------------\n",
      "TRAINING\n",
      "Rew:-21.18 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-23.05 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 17, num episode 1440-----------------------------------\n",
      "TRAINING\n",
      "Rew:-18.31 \n",
      "Steps per episode:99.98 \n",
      "Success rate:1.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-24.15 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 18, num episode 1520-----------------------------------\n",
      "TRAINING\n",
      "Rew:-18.5 \n",
      "Steps per episode:99.98 \n",
      "Success rate:1.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-17.07 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 19, num episode 1600-----------------------------------\n",
      "TRAINING\n",
      "Rew:-20.49 \n",
      "Steps per episode:99.58 \n",
      "Success rate:1.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-14.9 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 20, num episode 1681-----------------------------------\n",
      "TRAINING\n",
      "Rew:-11.97 \n",
      "Steps per episode:99.36 \n",
      "Success rate:3.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-12.77 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 21, num episode 1761-----------------------------------\n",
      "TRAINING\n",
      "Rew:-7.97 \n",
      "Steps per episode:99.66 \n",
      "Success rate:2.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-23.47 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 22, num episode 1841-----------------------------------\n",
      "TRAINING\n",
      "Rew:-10.01 \n",
      "Steps per episode:99.34 \n",
      "Success rate:2.0%\n",
      "\n",
      "TESTING\n",
      "Rew:10.18 \n",
      "Steps per episode:96.33 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 23, num episode 1922-----------------------------------\n",
      "TRAINING\n",
      "Rew:-2.47 \n",
      "Steps per episode:98.88 \n",
      "Success rate:5.0%\n",
      "\n",
      "TESTING\n",
      "Rew:22.74 \n",
      "Steps per episode:98.0 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 24, num episode 2005-----------------------------------\n",
      "TRAINING\n",
      "Rew:5.54 \n",
      "Steps per episode:97.74 \n",
      "Success rate:8.0%\n",
      "\n",
      "TESTING\n",
      "Rew:10.83 \n",
      "Steps per episode:97.67 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 25, num episode 2086-----------------------------------\n",
      "TRAINING\n",
      "Rew:11.4 \n",
      "Steps per episode:98.27 \n",
      "Success rate:10.0%\n",
      "\n",
      "TESTING\n",
      "Rew:-10.36 \n",
      "Steps per episode:100.0 \n",
      "Success rate:0.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 26, num episode 2170-----------------------------------\n",
      "TRAINING\n",
      "Rew:13.62 \n",
      "Steps per episode:96.75 \n",
      "Success rate:12.0%\n",
      "\n",
      "TESTING\n",
      "Rew:45.27 \n",
      "Steps per episode:93.11 \n",
      "Success rate:22.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 27, num episode 2257-----------------------------------\n",
      "TRAINING\n",
      "Rew:48.48 \n",
      "Steps per episode:91.4 \n",
      "Success rate:26.0%\n",
      "\n",
      "TESTING\n",
      "Rew:37.35 \n",
      "Steps per episode:92.89 \n",
      "Success rate:22.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 28, num episode 2343-----------------------------------\n",
      "TRAINING\n",
      "Rew:39.02 \n",
      "Steps per episode:92.53 \n",
      "Success rate:24.0%\n",
      "\n",
      "TESTING\n",
      "Rew:85.44 \n",
      "Steps per episode:80.78 \n",
      "Success rate:44.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 29, num episode 2436-----------------------------------\n",
      "TRAINING\n",
      "Rew:75.71 \n",
      "Steps per episode:86.37 \n",
      "Success rate:39.0%\n",
      "\n",
      "TESTING\n",
      "Rew:87.07 \n",
      "Steps per episode:82.89 \n",
      "Success rate:44.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 30, num episode 2525-----------------------------------\n",
      "TRAINING\n",
      "Rew:55.62 \n",
      "Steps per episode:91.12 \n",
      "Success rate:28.000000000000004%\n",
      "\n",
      "TESTING\n",
      "Rew:109.6 \n",
      "Steps per episode:79.67 \n",
      "Success rate:56.00000000000001%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 31, num episode 2614-----------------------------------\n",
      "TRAINING\n",
      "Rew:72.3 \n",
      "Steps per episode:89.9 \n",
      "Success rate:35.0%\n",
      "\n",
      "TESTING\n",
      "Rew:21.96 \n",
      "Steps per episode:95.78 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 32, num episode 2700-----------------------------------\n",
      "TRAINING\n",
      "Rew:44.2 \n",
      "Steps per episode:91.17 \n",
      "Success rate:24.0%\n",
      "\n",
      "TESTING\n",
      "Rew:135.47 \n",
      "Steps per episode:79.33 \n",
      "Success rate:67.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 33, num episode 2791-----------------------------------\n",
      "TRAINING\n",
      "Rew:62.52 \n",
      "Steps per episode:88.71 \n",
      "Success rate:33.0%\n",
      "\n",
      "TESTING\n",
      "Rew:58.5 \n",
      "Steps per episode:88.11 \n",
      "Success rate:33.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 34, num episode 2886-----------------------------------\n",
      "TRAINING\n",
      "Rew:78.12 \n",
      "Steps per episode:83.85 \n",
      "Success rate:39.0%\n",
      "\n",
      "TESTING\n",
      "Rew:45.65 \n",
      "Steps per episode:91.78 \n",
      "Success rate:22.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 35, num episode 2977-----------------------------------\n",
      "TRAINING\n",
      "Rew:68.78 \n",
      "Steps per episode:88.21 \n",
      "Success rate:33.0%\n",
      "\n",
      "TESTING\n",
      "Rew:111.92 \n",
      "Steps per episode:78.11 \n",
      "Success rate:56.00000000000001%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 36, num episode 3065-----------------------------------\n",
      "TRAINING\n",
      "Rew:66.32 \n",
      "Steps per episode:88.97 \n",
      "Success rate:31.0%\n",
      "\n",
      "TESTING\n",
      "Rew:62.19 \n",
      "Steps per episode:82.67 \n",
      "Success rate:33.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 37, num episode 3158-----------------------------------\n",
      "TRAINING\n",
      "Rew:74.42 \n",
      "Steps per episode:85.5 \n",
      "Success rate:37.0%\n",
      "\n",
      "TESTING\n",
      "Rew:134.42 \n",
      "Steps per episode:72.22 \n",
      "Success rate:67.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 38, num episode 3255-----------------------------------\n",
      "TRAINING\n",
      "Rew:92.73 \n",
      "Steps per episode:83.31 \n",
      "Success rate:46.0%\n",
      "\n",
      "TESTING\n",
      "Rew:62.88 \n",
      "Steps per episode:96.22 \n",
      "Success rate:33.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 39, num episode 3345-----------------------------------\n",
      "TRAINING\n",
      "Rew:57.7 \n",
      "Steps per episode:89.52 \n",
      "Success rate:28.999999999999996%\n",
      "\n",
      "TESTING\n",
      "Rew:70.22 \n",
      "Steps per episode:88.89 \n",
      "Success rate:33.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 40, num episode 3433-----------------------------------\n",
      "TRAINING\n",
      "Rew:43.48 \n",
      "Steps per episode:91.14 \n",
      "Success rate:25.0%\n",
      "\n",
      "TESTING\n",
      "Rew:42.13 \n",
      "Steps per episode:91.0 \n",
      "Success rate:22.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 41, num episode 3520-----------------------------------\n",
      "TRAINING\n",
      "Rew:41.32 \n",
      "Steps per episode:91.71 \n",
      "Success rate:24.0%\n",
      "\n",
      "TESTING\n",
      "Rew:15.75 \n",
      "Steps per episode:99.33 \n",
      "Success rate:11.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 42, num episode 3609-----------------------------------\n",
      "TRAINING\n",
      "Rew:49.81 \n",
      "Steps per episode:89.65 \n",
      "Success rate:26.0%\n",
      "\n",
      "TESTING\n",
      "Rew:58.88 \n",
      "Steps per episode:88.56 \n",
      "Success rate:33.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 43, num episode 3701-----------------------------------\n",
      "TRAINING\n",
      "Rew:75.62 \n",
      "Steps per episode:87.47 \n",
      "Success rate:39.0%\n",
      "\n",
      "TESTING\n",
      "Rew:127.95 \n",
      "Steps per episode:73.11 \n",
      "Success rate:67.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 44, num episode 3795-----------------------------------\n",
      "TRAINING\n",
      "Rew:83.57 \n",
      "Steps per episode:84.37 \n",
      "Success rate:42.0%\n",
      "\n",
      "TESTING\n",
      "Rew:82.78 \n",
      "Steps per episode:81.11 \n",
      "Success rate:44.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 45, num episode 3891-----------------------------------\n",
      "TRAINING\n",
      "Rew:85.58 \n",
      "Steps per episode:84.29 \n",
      "Success rate:45.0%\n",
      "\n",
      "TESTING\n",
      "Rew:53.08 \n",
      "Steps per episode:86.0 \n",
      "Success rate:33.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 46, num episode 3983-----------------------------------\n",
      "TRAINING\n",
      "Rew:75.6 \n",
      "Steps per episode:87.04 \n",
      "Success rate:42.0%\n",
      "\n",
      "TESTING\n",
      "Rew:64.19 \n",
      "Steps per episode:89.78 \n",
      "Success rate:33.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 47, num episode 4079-----------------------------------\n",
      "TRAINING\n",
      "Rew:78.07 \n",
      "Steps per episode:84.39 \n",
      "Success rate:42.0%\n",
      "\n",
      "TESTING\n",
      "Rew:83.37 \n",
      "Steps per episode:85.56 \n",
      "Success rate:44.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 48, num episode 4172-----------------------------------\n",
      "TRAINING\n",
      "Rew:74.31 \n",
      "Steps per episode:85.36 \n",
      "Success rate:39.0%\n",
      "\n",
      "TESTING\n",
      "Rew:72.8 \n",
      "Steps per episode:91.44 \n",
      "Success rate:33.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 49, num episode 4269-----------------------------------\n",
      "TRAINING\n",
      "Rew:75.09 \n",
      "Steps per episode:82.74 \n",
      "Success rate:41.0%\n",
      "\n",
      "TESTING\n",
      "Rew:67.36 \n",
      "Steps per episode:92.89 \n",
      "Success rate:33.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 50, num episode 4368-----------------------------------\n",
      "TRAINING\n",
      "Rew:92.7 \n",
      "Steps per episode:80.75 \n",
      "Success rate:46.0%\n",
      "\n",
      "TESTING\n",
      "Rew:108.77 \n",
      "Steps per episode:79.56 \n",
      "Success rate:56.00000000000001%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 51, num episode 4465-----------------------------------\n",
      "TRAINING\n",
      "Rew:94.21 \n",
      "Steps per episode:82.4 \n",
      "Success rate:47.0%\n",
      "\n",
      "TESTING\n",
      "Rew:87.59 \n",
      "Steps per episode:81.33 \n",
      "Success rate:44.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 52, num episode 4562-----------------------------------\n",
      "TRAINING\n",
      "Rew:90.06 \n",
      "Steps per episode:82.77 \n",
      "Success rate:46.0%\n",
      "\n",
      "TESTING\n",
      "Rew:37.51 \n",
      "Steps per episode:88.44 \n",
      "Success rate:22.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 53, num episode 4662-----------------------------------\n",
      "TRAINING\n",
      "Rew:103.96 \n",
      "Steps per episode:80.17 \n",
      "Success rate:52.0%\n",
      "\n",
      "TESTING\n",
      "Rew:88.86 \n",
      "Steps per episode:76.33 \n",
      "Success rate:44.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 54, num episode 4757-----------------------------------\n",
      "TRAINING\n",
      "Rew:80.97 \n",
      "Steps per episode:83.47 \n",
      "Success rate:42.0%\n",
      "\n",
      "TESTING\n",
      "Rew:154.55 \n",
      "Steps per episode:65.44 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 55, num episode 4864-----------------------------------\n",
      "TRAINING\n",
      "Rew:116.14 \n",
      "Steps per episode:75.3 \n",
      "Success rate:57.99999999999999%\n",
      "\n",
      "TESTING\n",
      "Rew:137.97 \n",
      "Steps per episode:75.22 \n",
      "Success rate:67.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 56, num episode 4974-----------------------------------\n",
      "TRAINING\n",
      "Rew:133.79 \n",
      "Steps per episode:72.73 \n",
      "Success rate:67.0%\n",
      "\n",
      "TESTING\n",
      "Rew:128.78 \n",
      "Steps per episode:74.44 \n",
      "Success rate:67.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 57, num episode 5080-----------------------------------\n",
      "TRAINING\n",
      "Rew:123.45 \n",
      "Steps per episode:75.26 \n",
      "Success rate:61.0%\n",
      "\n",
      "TESTING\n",
      "Rew:83.69 \n",
      "Steps per episode:82.67 \n",
      "Success rate:44.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 58, num episode 5189-----------------------------------\n",
      "TRAINING\n",
      "Rew:132.13 \n",
      "Steps per episode:72.8 \n",
      "Success rate:65.0%\n",
      "\n",
      "TESTING\n",
      "Rew:110.72 \n",
      "Steps per episode:74.67 \n",
      "Success rate:56.00000000000001%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 59, num episode 5297-----------------------------------\n",
      "TRAINING\n",
      "Rew:130.01 \n",
      "Steps per episode:74.07 \n",
      "Success rate:67.0%\n",
      "\n",
      "TESTING\n",
      "Rew:178.41 \n",
      "Steps per episode:62.56 \n",
      "Success rate:89.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 60, num episode 5418-----------------------------------\n",
      "TRAINING\n",
      "Rew:151.53 \n",
      "Steps per episode:66.72 \n",
      "Success rate:76.0%\n",
      "\n",
      "TESTING\n",
      "Rew:147.82 \n",
      "Steps per episode:73.78 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 61, num episode 5536-----------------------------------\n",
      "TRAINING\n",
      "Rew:147.43 \n",
      "Steps per episode:67.74 \n",
      "Success rate:74.0%\n",
      "\n",
      "TESTING\n",
      "Rew:162.37 \n",
      "Steps per episode:63.67 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 62, num episode 5656-----------------------------------\n",
      "TRAINING\n",
      "Rew:152.64 \n",
      "Steps per episode:66.38 \n",
      "Success rate:76.0%\n",
      "\n",
      "TESTING\n",
      "Rew:135.26 \n",
      "Steps per episode:65.44 \n",
      "Success rate:67.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 63, num episode 5768-----------------------------------\n",
      "TRAINING\n",
      "Rew:139.9 \n",
      "Steps per episode:71.31 \n",
      "Success rate:70.0%\n",
      "\n",
      "TESTING\n",
      "Rew:152.64 \n",
      "Steps per episode:63.11 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 64, num episode 5893-----------------------------------\n",
      "TRAINING\n",
      "Rew:166.04 \n",
      "Steps per episode:64.56 \n",
      "Success rate:84.0%\n",
      "\n",
      "TESTING\n",
      "Rew:150.9 \n",
      "Steps per episode:62.11 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 65, num episode 6028-----------------------------------\n",
      "TRAINING\n",
      "Rew:166.71 \n",
      "Steps per episode:58.9 \n",
      "Success rate:84.0%\n",
      "\n",
      "TESTING\n",
      "Rew:197.1 \n",
      "Steps per episode:58.0 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 66, num episode 6174-----------------------------------\n",
      "TRAINING\n",
      "Rew:175.11 \n",
      "Steps per episode:55.12 \n",
      "Success rate:88.0%\n",
      "\n",
      "TESTING\n",
      "Rew:201.25 \n",
      "Steps per episode:50.67 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 67, num episode 6319-----------------------------------\n",
      "TRAINING\n",
      "Rew:173.52 \n",
      "Steps per episode:54.98 \n",
      "Success rate:87.0%\n",
      "\n",
      "TESTING\n",
      "Rew:154.71 \n",
      "Steps per episode:71.33 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 68, num episode 6461-----------------------------------\n",
      "TRAINING\n",
      "Rew:177.42 \n",
      "Steps per episode:56.09 \n",
      "Success rate:89.0%\n",
      "\n",
      "TESTING\n",
      "Rew:158.92 \n",
      "Steps per episode:70.44 \n",
      "Success rate:78.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 69, num episode 6613-----------------------------------\n",
      "TRAINING\n",
      "Rew:180.05 \n",
      "Steps per episode:52.71 \n",
      "Success rate:90.0%\n",
      "\n",
      "TESTING\n",
      "Rew:177.33 \n",
      "Steps per episode:49.56 \n",
      "Success rate:89.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 70, num episode 6767-----------------------------------\n",
      "TRAINING\n",
      "Rew:190.2 \n",
      "Steps per episode:52.03 \n",
      "Success rate:95.0%\n",
      "\n",
      "TESTING\n",
      "Rew:197.83 \n",
      "Steps per episode:48.89 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 71, num episode 6943-----------------------------------\n",
      "TRAINING\n",
      "Rew:193.65 \n",
      "Steps per episode:45.62 \n",
      "Success rate:97.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.24 \n",
      "Steps per episode:49.89 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 72, num episode 7114-----------------------------------\n",
      "TRAINING\n",
      "Rew:187.59 \n",
      "Steps per episode:46.53 \n",
      "Success rate:94.0%\n",
      "\n",
      "TESTING\n",
      "Rew:203.56 \n",
      "Steps per episode:40.22 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 73, num episode 7297-----------------------------------\n",
      "TRAINING\n",
      "Rew:198.06 \n",
      "Steps per episode:44.01 \n",
      "Success rate:99.0%\n",
      "\n",
      "TESTING\n",
      "Rew:201.82 \n",
      "Steps per episode:51.0 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 74, num episode 7501-----------------------------------\n",
      "TRAINING\n",
      "Rew:196.44 \n",
      "Steps per episode:39.21 \n",
      "Success rate:99.0%\n",
      "\n",
      "TESTING\n",
      "Rew:197.75 \n",
      "Steps per episode:42.11 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 75, num episode 7697-----------------------------------\n",
      "TRAINING\n",
      "Rew:197.69 \n",
      "Steps per episode:40.8 \n",
      "Success rate:99.0%\n",
      "\n",
      "TESTING\n",
      "Rew:197.33 \n",
      "Steps per episode:36.78 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 76, num episode 7912-----------------------------------\n",
      "TRAINING\n",
      "Rew:197.97 \n",
      "Steps per episode:37.01 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.31 \n",
      "Steps per episode:35.22 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 77, num episode 8135-----------------------------------\n",
      "TRAINING\n",
      "Rew:196.38 \n",
      "Steps per episode:35.99 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:199.03 \n",
      "Steps per episode:40.0 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 78, num episode 8387-----------------------------------\n",
      "TRAINING\n",
      "Rew:197.07 \n",
      "Steps per episode:31.79 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:175.94 \n",
      "Steps per episode:34.78 \n",
      "Success rate:89.0%\n",
      "\n",
      "\n",
      "-----------------------------------ITERATION 79, num episode 8645-----------------------------------\n",
      "TRAINING\n",
      "Rew:197.03 \n",
      "Steps per episode:31.03 \n",
      "Success rate:100.0%\n",
      "\n",
      "TESTING\n",
      "Rew:198.13 \n",
      "Steps per episode:25.22 \n",
      "Success rate:100.0%\n",
      "\n",
      "\n",
      "Model saved into /home/terra/Desktop/magistrale/distributed_ai_project/src/policies/PPO/env_7_pomdp/models/looseplay_2agents_densereward_run_3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8175481ae354762aaa74e1c4bfb95eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Episodes</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Testing_reward_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Testing_steps_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Testing_success_rate_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Training_reward_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Training_steps_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Training_success_rate_per_episode</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Episodes</td><td>8645</td></tr><tr><td>Testing_reward_per_episode</td><td>198.13</td></tr><tr><td>Testing_steps_per_episode</td><td>25.22</td></tr><tr><td>Testing_success_rate_per_episode</td><td>100.0</td></tr><tr><td>Training_reward_per_episode</td><td>197.03</td></tr><tr><td>Training_steps_per_episode</td><td>31.03</td></tr><tr><td>Training_success_rate_per_episode</td><td>100.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_3</strong> at: <a href='https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents/runs/meo098rm' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents/runs/meo098rm</a><br/> View project at: <a href='https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents' target=\"_blank\">https://wandb.ai/299011-unimore/gridworld_pomdp_looseplay_2agents</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260102_231115-meo098rm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "group_name = \"dense\"\n",
    "\n",
    "for run_idx in range(2,4):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"RUN NUMBER {run_idx}/3\")\n",
    "    print(f\"{'='*40}\\n\")\n",
    "\n",
    "    ppo = config.build_algo()\n",
    "    wandb.init(\n",
    "        project=\"gridworld_pomdp_looseplay_2agents\",\n",
    "        group=group_name,           \n",
    "        name=f\"run_{run_idx}\",    \n",
    "        reinit=True \n",
    "    )\n",
    "    file_name = f\"{under_examination}_run_{run_idx}\"\n",
    "    \n",
    "    num_total_episodes = 0\n",
    "    for i in range(80):\n",
    "        result = ppo.train()\n",
    "        num_total_episodes += result['env_runners']['num_episodes']\n",
    "        \n",
    "        print(f\"ITERATION {i}, num episode {num_total_episodes}\".center(100,\"-\"))\n",
    "        train_rew = round(result['env_runners']['episode_return_mean'], 2)\n",
    "        train_steps_episode = round(result['env_runners']['episode_len_mean'], 2)\n",
    "        train_success_rate = round(result['env_runners']['custom_metrics'].get('success_rate_mean', 0), 2) * 100\n",
    "        print(f\"\"\"TRAINING\\nRew:{train_rew} \\nSteps per episode:{train_steps_episode} \\nSuccess rate:{train_success_rate}%\\n\"\"\")\n",
    "\n",
    "        if 'evaluation' in result:\n",
    "            testing_rew = round(result['evaluation']['env_runners']['episode_return_mean'], 2)\n",
    "            testing_steps_episode = round(result['evaluation']['env_runners']['episode_len_mean'], 2)\n",
    "            testing_success_rate = round(result['evaluation']['env_runners']['custom_metrics'].get('success_rate_mean', 0), 2) * 100\n",
    "            print(f\"\"\"TESTING\\nRew:{testing_rew} \\nSteps per episode:{testing_steps_episode} \\nSuccess rate:{testing_success_rate}%\\n\\n\"\"\")\n",
    "\n",
    "        log_data = {\n",
    "            \"Episodes\": num_total_episodes,\n",
    "\n",
    "            \"Training_steps_per_episode\": train_steps_episode,\n",
    "            \"Training_success_rate_per_episode\": train_success_rate,\n",
    "            \"Training_reward_per_episode\": train_rew,\n",
    "\n",
    "            \"Testing_steps_per_episode\": testing_steps_episode,\n",
    "            \"Testing_success_rate_per_episode\": testing_success_rate,\n",
    "            \"Testing_reward_per_episode\": testing_rew\n",
    "        }\n",
    "        wandb.log(log_data)\n",
    "    save_model(ppo, file_name)\n",
    "    wandb.finish()\n",
    "\n",
    "print(\"FINISHED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3738be",
   "metadata": {},
   "source": [
    "## **Load agents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2029a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.ppo import PPO\n",
    "import os\n",
    "\n",
    "def load_model(file_name):\n",
    "    current_dir = os.getcwd()\n",
    "    model_dir = os.path.join(current_dir, \"models\")\n",
    "    checkpoint_name = os.path.join(model_dir, file_name)\n",
    "\n",
    "    ppo = PPO.from_checkpoint(checkpoint_name)\n",
    "    return ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59369442",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     11\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, matching_file)\n\u001b[0;32m---> 12\u001b[0m ppo \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m(file_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "model_dir = os.path.join(current_dir, \"models\")\n",
    "\n",
    "for filename in os.listdir(model_dir):\n",
    "    if \"best\" in filename and under_examination in filename:\n",
    "        matching_file = filename\n",
    "        break\n",
    "\n",
    "file_path = os.path.join(model_dir, matching_file)\n",
    "ppo = load_model(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c4cf2",
   "metadata": {},
   "source": [
    "## **Graphically test the agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f542a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Sprite image /home/terra/Desktop/magistrale/distributed_ai_project/sprites/.png not found. Using default sprite for this simulation.\n",
      "WARNING! Sprite image /home/terra/Desktop/magistrale/distributed_ai_project/sprites/.png not found. Using default sprite for this simulation.\n",
      "{'agent1': array([ 1., -2., 28., 28., 28., 28., 28., 28., -1.], dtype=float32), 'agent2': array([-1.,  2., 28., 28., 28., 28.,  3., -1.,  0.], dtype=float32)}\n",
      "{'agent1': array([ 2., -2., 28., 28., 28., 28., 28., 28., -1.], dtype=float32), 'agent2': array([-2.,  2.,  4.,  1., 28., 28.,  2., -1.,  0.], dtype=float32)}\n",
      "{'agent1': array([ 3., -2., 28., 28., 28., 28., 28., 28., -1.], dtype=float32), 'agent2': array([-3.,  2.,  3.,  1., 28., 28.,  1., -1.,  0.], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "env = MyGridWorld(grid_size=15, n_agents=2, render_mode=\"human\")\n",
    "obs, _ = env.reset()\n",
    "\n",
    "# Initialize lstm, previous actions and rewards\n",
    "lstm_states = {agent_id: [np.zeros(128), np.zeros(128)] for agent_id in env.possible_agents}  # 128 = lstm_cell_size\n",
    "prev_actions = {agent_id: 0 for agent_id in env.possible_agents}                              # 0 as defualt previous action\n",
    "prev_rewards = {agent_id: 0.0 for agent_id in env.possible_agents}                            # 0 as default previous reward\n",
    "\n",
    "num_episodes = 0\n",
    "while num_episodes<3:\n",
    "    actions = {}\n",
    "\n",
    "    for agent_id, agent_obs in obs.items():\n",
    "        action, new_state, _ = ppo.get_policy(agent_id).compute_single_action(\n",
    "            obs=agent_obs,\n",
    "            state=lstm_states[agent_id],\n",
    "            prev_action=prev_actions[agent_id],\n",
    "            prev_reward=prev_rewards[agent_id],\n",
    "            explore=True\n",
    "        )\n",
    "        actions[agent_id] = action\n",
    "        lstm_states[agent_id] = new_state  # update lstm states\n",
    "\n",
    "    obs, rewards, terminations, truncations, infos = env.step(actions)\n",
    "\n",
    "    # update prev_actions e prev_rewards\n",
    "    for agent_id in obs.keys():\n",
    "        prev_actions[agent_id] = actions[agent_id]\n",
    "        prev_rewards[agent_id] = rewards[agent_id]\n",
    "\n",
    "    if any(terminations.values()) or any(truncations.values()):\n",
    "        obs, _ = env.reset()\n",
    "        # reset lstm states, previous actions and rewards\n",
    "        lstm_states = {agent_id: [np.zeros(128), np.zeros(128)] for agent_id in env.possible_agents}\n",
    "        prev_actions = {agent_id: 0 for agent_id in env.possible_agents}\n",
    "        prev_rewards = {agent_id: 0.0 for agent_id in env.possible_agents}\n",
    "        num_episodes += 1\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da8e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MARL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
